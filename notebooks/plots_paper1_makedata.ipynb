{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f329a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.paths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridspec\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgd\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SetupPaths\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m  \u001b[38;5;21;01mmpatches\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FormatStrFormatter\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.paths'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os.path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gd\n",
    "from utils.paths import SetupPaths\n",
    "import matplotlib.patches as  mpatches\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from utils.get_summary_data import compile_summary\n",
    "from utils.vectorCorrection import vectorCorrection as vector\n",
    "\n",
    "\n",
    "paths = SetupPaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d243c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show();\n",
    "plt.rcParams.update({'font.size':20,\"xtick.direction\":\"in\",\"ytick.direction\":\"in\", \n",
    "                     \"xtick.top\":True, \"ytick.right\":True,\"text.usetex\":False,\n",
    "                     \"xtick.labelsize\":18,\"ytick.labelsize\":18})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6e32267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining equivalent redshifts\n",
    "zs = {\"z\":np.array([0,1,2,3,4]), \n",
    "#       \"zill\":np.array([135,85,68,60,56]), \n",
    "      \"ztng\":np.array([99,50,33,25,21])}\n",
    "\n",
    "# defining color palette for plotting\n",
    "palette = {\"Illustris dark\": \"#009292\", \"Illustris hydro\": \"#B6DAFF\",\n",
    "           \"TNG dark\": \"#930200\", \"TNG hydro\": \"#FFB5DC\",\n",
    "           \"dwarf\":\"olive\",\"massive\":\"salmon\", \"difference\":\"#2C1D11\", \"difference2\":\"#464646\"}\n",
    "\n",
    "alphas = {\"maj\": 0.7, \"min\": 0.3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058a4bf",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6176d66c",
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "# make functions to get data at the requested snapshot\n",
    "def get_primmask(primstells, size):\n",
    "    if size == \"dwarf\":\n",
    "        mask = (primstells > 0.01) & (primstells < 0.5)\n",
    "    elif size == \"massive\":\n",
    "        mask = (primstells > 0.5) & (primstells < 10)\n",
    "    return mask\n",
    "\n",
    "def get_groupmask(groupmass, size):\n",
    "    if size == \"dwarf\":\n",
    "        mask = (groupmass > 8) & (groupmass < 50)\n",
    "    elif size == \"massive\":\n",
    "        mask = (groupmass > 100) & (groupmass < 650)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d704ccad",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EmptyFile(Exception): pass\n",
    "class SkipRedshift(Exception): pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0da322c",
   "metadata": {},
   "source": [
    "# Primary + Pair count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32443e18",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_counts( size, reals, errorprint=False, redshiftcutoff=True):    \n",
    "    snapshots = np.arange(0,100,1)\n",
    "    snapshots = np.delete(snapshots, np.where(snapshots==48)[0])\n",
    "    redcutoff = 4.2\n",
    "        \n",
    "    redshifts = []\n",
    "    medone, medtwo, medtot, medmaj, medmin, medpair, medmajfrac, medminfrac, medtotfrac = [], [], [], [], [], [], [], [], []\n",
    "    quartone, quarttwo, quarttot, quartmaj, quartmin, quartpair, quartmajfrac, quartminfrac, quarttotfrac = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    for snap in snapshots:  \n",
    "        singleprims, doubleprims, totalprims = [], [], []\n",
    "        majorpairs, minorpairs, totalpairs = [], [], []\n",
    "        majfrac, minfrac, totfrac = [], [], []\n",
    "        \n",
    "        try:\n",
    "            pair_path = f\"TNG_{snap}_{reals}.hdf5\"\n",
    "            pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "            \n",
    "            if np.size(pair_data) == 0:\n",
    "                raise EmptyFile\n",
    "                \n",
    "            redshift = pair_data['Header'].attrs['Redshift']\n",
    "            \n",
    "            if redshiftcutoff & ( redshift > redcutoff) :\n",
    "                raise SkipRedshift\n",
    "                \n",
    "            if (len(pair_data['pairs'][\"hydro\"]['Group ID']) == 0):    \n",
    "                raise EmptyFile\n",
    "                \n",
    "            unpair = pair_data[\"unpaired\"][\"hydro\"]\n",
    "            unpairStells = np.array(unpair[\"Sub1 Stellar Mass\"])\n",
    "            unpairGroups = np.array(unpair[\"Group Mass\"])\n",
    "            unpairReals = np.array(unpair['Realization'])\n",
    "            \n",
    "            pair = pair_data[\"pairs\"][\"hydro\"]\n",
    "            priStell = np.array(pair[\"Sub1 Stellar Mass\"])\n",
    "            secStell = np.array(pair[\"Sub2 Stellar Mass\"])\n",
    "            pairGroups = np.array(pair[\"Group Mass\"])\n",
    "            pairReals = np.array(pair[\"Realization\"])\n",
    "            seps = np.array(pair[\"Separation\"]) \n",
    "            \n",
    "            # subset masks for unpaired\n",
    "            unpair_pri = get_primmask(unpairStells, size)\n",
    "            unpair_group = get_groupmask(unpairGroups, size)                \n",
    "            \n",
    "            pair_pri = get_primmask(priStell, size)\n",
    "            pair_group = get_groupmask(pairGroups, size)\n",
    "\n",
    "            majors = (secStell/priStell > 1/4)\n",
    "            minors = (secStell/priStell > 1/10) & (secStell/priStell < 1/4)\n",
    "            allpairs = (majors + minors)\n",
    "            pair_lowsep = (seps > 10)\n",
    "\n",
    "            # defining combined masks \n",
    "            unpair_mask = unpair_pri & unpair_group\n",
    "            primary_mask = pair_pri & pair_group\n",
    "            pair_mask = pair_pri & pair_group & pair_lowsep & allpairs\n",
    "                                                           \n",
    "            for real in np.unique(unpairReals):                  \n",
    "                # make realization masks\n",
    "                unpair_real = unpairReals == real\n",
    "                pair_real = pairReals == real\n",
    "\n",
    "                # make count values for single realization\n",
    "                numone = np.count_nonzero(unpair_mask & unpair_real)\n",
    "                numtwo = np.count_nonzero(primary_mask & pair_real)\n",
    "                numtot = numone + numtwo\n",
    "                nummaj = np.count_nonzero(pair_mask & pair_real & majors)\n",
    "                nummin = np.count_nonzero(pair_mask & pair_real & minors)\n",
    "                numpair = np.count_nonzero(pair_mask & pair_real)\n",
    "                \n",
    "                if numtot == 0:\n",
    "                    continue\n",
    "                \n",
    "                # collect count vals for all reals\n",
    "                singleprims.append(numone)\n",
    "                doubleprims.append(numtwo)\n",
    "                totalprims.append(numtot)\n",
    "                majorpairs.append(nummaj)\n",
    "                minorpairs.append(nummin)\n",
    "                totalpairs.append(numpair)\n",
    "                majfrac.append(nummaj / numtot)\n",
    "                minfrac.append(nummin / numtot)\n",
    "                totfrac.append(numpair / numtot)\n",
    "\n",
    "            # create arrays of medians and quartiles~ \n",
    "            lower, upper = 0.5, 99.5                \n",
    "            redshifts.append( redshift )\n",
    "            medone.append(np.median( singleprims ))\n",
    "            medtwo.append(np.median( doubleprims ))\n",
    "            medtot.append(np.median( totalprims ))\n",
    "            medmaj.append(np.median( majorpairs ))\n",
    "            medmin.append(np.median( minorpairs ))\n",
    "            medpair.append(np.median( totalpairs ))\n",
    "            medmajfrac.append(np.median( majfrac ))\n",
    "            medminfrac.append(np.median( minfrac ))\n",
    "            medtotfrac.append(np.median( totfrac ))   \n",
    "            quartone.append( np.percentile( singleprims, [lower, upper]))\n",
    "            quarttwo.append( np.percentile( doubleprims, [lower, upper]))\n",
    "            quarttot.append( np.percentile( totalprims, [lower, upper]))\n",
    "            quartmaj.append( np.percentile( majorpairs, [lower, upper]))\n",
    "            quartmin.append( np.percentile( minorpairs, [lower, upper]))\n",
    "            quartpair.append( np.percentile( totalpairs, [lower, upper]))\n",
    "            quartmajfrac.append( np.percentile( majfrac, [lower, upper]))\n",
    "            quartminfrac.append( np.percentile( minfrac, [lower, upper]))\n",
    "            quarttotfrac.append( np.percentile( totfrac, [lower, upper]))\n",
    "                       \n",
    "        except KeyError:\n",
    "            if errorprint: print(f'skipping {snap} for KeyError. Please debug')\n",
    "            continue\n",
    "            \n",
    "        except EmptyFile:\n",
    "            if errorprint: print(f\"skipping {snap}, empty file\")\n",
    "            continue\n",
    "            \n",
    "        except SkipRedshift:\n",
    "            if errorprint: print(f\"skipping {snap}, redshift out of range\")\n",
    "                \n",
    "    count_dictionary = {\n",
    "            \"z\": np.array(redshifts),\n",
    "            \"Median Isolated Primaries\": np.array(medone),\n",
    "            \"Median Noniso Primaries\": np.array(medtwo),\n",
    "            \"Median Total Primaries\": np.array(medtot),\n",
    "            \"Median Major Pairs\": np.array(medmaj),\n",
    "            \"Median Minor Pairs\": np.array(medmin),\n",
    "            \"Median All Pairs\": np.array(medpair),\n",
    "            \"Median Major Fraction\": np.array(medmajfrac),\n",
    "            \"Median Minor Fraction\": np.array(medminfrac),\n",
    "            \"Median Total Fraction\": np.array(medtotfrac),\n",
    "            \"Quarts Isolated Primaries\": np.array(quartone),\n",
    "            \"Quarts Noniso Primaries\": np.array(quarttwo),\n",
    "            \"Quarts Total Primaries\": np.array(quarttot),\n",
    "            \"Quarts Major Pairs\": np.array(quartmaj),\n",
    "            \"Quarts Minor Pairs\": np.array(quartmin),\n",
    "            \"Quarts All Pairs\": np.array(quartpair),\n",
    "            \"Quarts Major Fraction\": np.array(quartmajfrac),\n",
    "            \"Quarts Minor Fraction\": np.array(quartminfrac),\n",
    "            \"Quarts Total Fraction\": np.array(quarttotfrac)}\n",
    "            \n",
    "    return count_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc50bd72",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_countdata(reals):\n",
    "    #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}counts.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(f\"{paths.path_plotdata}counts.hdf5\", 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"1000 Reals - Quartile Range\":\"0.5-99.5%\",\n",
    "                       \"Simulation\":\"TNG100-1 (Hydro)\"}\n",
    "\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(f\"{paths.path_plotdata}counts.hdf5\", 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        dwarfs = get_counts(\"dwarf\", reals)\n",
    "        print(\"finished creating dwarf tables\")\n",
    "        massives = get_counts(\"massive\", reals)\n",
    "        print(\"finished creating massive tables\")\n",
    "              \n",
    "        print(\"creating hdf5 structure\")\n",
    "        for size_data, size_name in zip([dwarfs,massives],[\"dwarf\",\"massive\"]):\n",
    "            for key, val in size_data.items():\n",
    "                val = np.array(val)\n",
    "                dset = f.create_dataset(f'/{reals} Realizations/{size_name}/{key}', \n",
    "                                        shape=val.shape,\n",
    "                                        dtype=val.dtype)\n",
    "                dset[:] = val\n",
    "                \n",
    "        f.close()\n",
    "        print(\"data saved~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f0c67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n"
     ]
    }
   ],
   "source": [
    "make_countdata(10)\n",
    "make_countdata(100)\n",
    "make_countdata(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7993a",
   "metadata": {},
   "source": [
    "# Mass ratio distribuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eeae204",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_smr(size, z, reals):\n",
    "    zloc = np.where( zs['z'] == z)[0]\n",
    "    sim = \"TNG\"\n",
    "    snapshot = zs['ztng'][zloc][0] \n",
    "\n",
    "    pair_path = f\"{sim}_{snapshot}_{reals}.hdf5\"\n",
    "    pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "    \n",
    "    pairs = pair_data[\"pairs\"][\"hydro\"]\n",
    "\n",
    "    pri_stell = np.array(pairs[\"Sub1 Stellar Mass\"])\n",
    "    sec_stell = np.array(pairs[\"Sub2 Stellar Mass\"])\n",
    "    seps = np.array(pairs[\"Separation\"]) \n",
    "\n",
    "    # masks            \n",
    "    pair_pri = get_primmask(pri_stell, size)\n",
    "    pair_group = get_groupmask(np.array(pairs[\"Group Mass\"]), size)\n",
    "    pair_sepcut = seps > 10\n",
    "    \n",
    "    majors = (sec_stell/pri_stell > 1/4)\n",
    "    minors = (sec_stell/pri_stell > 1/10) & (sec_stell/pri_stell < 1/4)\n",
    "\n",
    "    pair_mask = pair_pri & pair_group & pair_sepcut\n",
    "\n",
    "    major_mask = pair_mask & majors\n",
    "    minor_mask = pair_mask & minors\n",
    "\n",
    "    majors = np.array(pairs[\"Stellar Mass Ratio\"])[major_mask]\n",
    "    minors = np.array(pairs[\"Stellar Mass Ratio\"])[minor_mask]\n",
    "\n",
    "    key_dict = {\"major\":majors, \"minor\":minors}\n",
    "    \n",
    "\n",
    "    return key_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd8d18c3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_smrdata(reals):\n",
    "    #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}smr.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"Simulation\":\"TNG100-1 (Hydro)\"}\n",
    "\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        for z in zs[\"z\"]:\n",
    "            dwarf = get_smr(\"dwarf\", z, reals)\n",
    "            massive = get_smr(\"massive\", z, reals)\n",
    "            print(f\"finished z={z}\")\n",
    "              \n",
    "            for size_data, size_name in zip([dwarf,massive],[\"dwarf\",\"massive\"]):\n",
    "                for key, val in size_data.items():\n",
    "                    val = np.array(val)\n",
    "                    dset = f.create_dataset(f'/{reals} Realizations/z={z}/{size_name}/{key}', \n",
    "                                            shape=val.shape,\n",
    "                                            dtype=val.dtype)\n",
    "                    dset[:] = val\n",
    "        print(\"data saved\")        \n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a668fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist...\n",
      "creating file\n",
      "file created successfully. adding header...\n",
      "header added successfully\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "make_smrdata(10)\n",
    "make_smrdata(100)\n",
    "make_smrdata(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39917e82",
   "metadata": {},
   "source": [
    "# Pair fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3185c35a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_pairfrac(reals, errorprint=False, redshiftcutoff=True):    \n",
    "    snapshots = np.arange(0,100,1)\n",
    "    snapshots = np.delete(snapshots, np.where(snapshots==48)[0])\n",
    "    redcutoff = 4.2\n",
    "        \n",
    "    redshifts = []\n",
    "    medfrac_majdw, medfrac_mindw, medfrac_majma, medfrac_minma  = [], [], [], []\n",
    "    quartfrac_majdw, quartfrac_mindw, quartfrac_majma, quartfrac_minma = [], [], [], []\n",
    "    medfrac_majdiff, medfrac_mindiff, quartfrac_majdiff, quartfrac_mindiff  = [], [], [], []\n",
    "\n",
    "    for snap in snapshots:  \n",
    "        frac_majdw, frac_mindw, frac_majma, frac_minma = [], [], [], []\n",
    "        frac_majdiff, frac_mindiff = [], []\n",
    "        \n",
    "        try:\n",
    "            pair_path = f\"TNG_{snap}_{reals}.hdf5\"\n",
    "            pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "            \n",
    "            if np.size(pair_data) == 0:\n",
    "                raise EmptyFile\n",
    "                \n",
    "            redshift = pair_data['Header'].attrs['Redshift']\n",
    "            \n",
    "            if redshiftcutoff & ( redshift > redcutoff) :\n",
    "                raise SkipRedshift\n",
    "                \n",
    "            if (len(pair_data['pairs'][\"hydro\"]['Group ID']) == 0):    \n",
    "                raise EmptyFile\n",
    "            \n",
    "            unpair = pair_data[\"unpaired\"][\"hydro\"]\n",
    "            unpairStells = np.array(unpair[\"Sub1 Stellar Mass\"])\n",
    "            unpairGroups = np.array(unpair[\"Group Mass\"])\n",
    "            unpairReals = np.array(unpair['Realization'])\n",
    "            \n",
    "            pair = pair_data[\"pairs\"][\"hydro\"]\n",
    "            priStell = np.array(pair[\"Sub1 Stellar Mass\"])\n",
    "            secStell = np.array(pair[\"Sub2 Stellar Mass\"])\n",
    "            pairGroups = np.array(pair[\"Group Mass\"])\n",
    "            pairReals = np.array(pair[\"Realization\"])\n",
    "            seps = np.array(pair[\"Separation\"]) \n",
    "            \n",
    "            # subset masks for unpaired\n",
    "            majors = (secStell/priStell > 1/4)\n",
    "            minors = (secStell/priStell > 1/10) & (secStell/priStell < 1/4)\n",
    "            allpairs = (majors + minors)\n",
    "            pair_lowsep = (seps > 10)\n",
    "            \n",
    "            ## dwarfs\n",
    "            unpair_pri_dwarf = get_primmask(unpairStells, \"dwarf\")\n",
    "            unpair_group_dwarf = get_groupmask(unpairGroups, \"dwarf\")                \n",
    "            \n",
    "            pair_pri_dwarf = get_primmask(priStell, \"dwarf\")\n",
    "            pair_group_dwarf = get_groupmask(pairGroups, \"dwarf\")\n",
    "            \n",
    "                # defining combined masks \n",
    "            unpair_mask_dwarf = unpair_pri_dwarf & unpair_group_dwarf\n",
    "            primary_mask_dwarf = pair_pri_dwarf & pair_group_dwarf\n",
    "            pair_mask_dwarf = pair_pri_dwarf & pair_group_dwarf & pair_lowsep & allpairs\n",
    "            \n",
    "            ## massive\n",
    "            unpair_pri_massive = get_primmask(unpairStells, \"massive\")\n",
    "            unpair_group_massive = get_groupmask(unpairGroups, \"massive\")                \n",
    "            \n",
    "            pair_pri_massive = get_primmask(priStell, \"massive\")\n",
    "            pair_group_massive = get_groupmask(pairGroups, \"massive\")\n",
    "\n",
    "                # defining combined masks \n",
    "            unpair_mask_massive = unpair_pri_massive & unpair_group_massive\n",
    "            primary_mask_massive = pair_pri_massive & pair_group_massive\n",
    "            pair_mask_massive = pair_pri_massive & pair_group_massive & pair_lowsep & allpairs\n",
    "                                                          \n",
    "            for real in np.unique(unpairReals):                  \n",
    "                # make realization masks\n",
    "                unpair_real = unpairReals == real\n",
    "                pair_real = pairReals == real\n",
    "\n",
    "                # make count values for single realization\n",
    "                numone_dwarf = np.count_nonzero(unpair_mask_dwarf & unpair_real)\n",
    "                numtwo_dwarf = np.count_nonzero(primary_mask_dwarf & pair_real)\n",
    "                numtot_dwarf = numone_dwarf + numtwo_dwarf\n",
    "                nummaj_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & majors)\n",
    "                nummin_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & minors)\n",
    "                numpair_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real)\n",
    "                \n",
    "                # make count values for single realization\n",
    "                numone_massive = np.count_nonzero(unpair_mask_massive & unpair_real)\n",
    "                numtwo_massive = np.count_nonzero(primary_mask_massive & pair_real)\n",
    "                numtot_massive = numone_massive + numtwo_massive\n",
    "                nummaj_massive = np.count_nonzero(pair_mask_massive & pair_real & majors)\n",
    "                nummin_massive = np.count_nonzero(pair_mask_massive & pair_real & minors)\n",
    "                numpair_massive = np.count_nonzero(pair_mask_massive & pair_real)\n",
    "                \n",
    "                if (numtot_dwarf == 0) or (numtot_massive == 0):\n",
    "                    continue\n",
    "                    \n",
    "                # collect vals for all reals\n",
    "                frac_majdw.append( nummaj_dwarf/numtot_dwarf ) \n",
    "                frac_mindw.append( nummin_dwarf/numtot_dwarf ) \n",
    "                frac_majma.append( nummaj_massive/numtot_massive ) \n",
    "                frac_minma.append( nummin_massive/numtot_massive ) \n",
    "                frac_majdiff.append( (nummaj_massive/numtot_massive) - (nummaj_dwarf/numtot_dwarf) ) \n",
    "                frac_mindiff.append( (nummin_massive/numtot_massive) - (nummaj_dwarf/numtot_dwarf) ) \n",
    "                    \n",
    "            # create arrays of medians and quartiles~ \n",
    "            lower, upper = 0.5, 99.5                \n",
    "            redshifts.append( redshift )\n",
    "            \n",
    "            medfrac_majdw.append( np.median( frac_majdw ) )\n",
    "            medfrac_mindw.append( np.median( frac_mindw ) )\n",
    "            medfrac_majma.append( np.median( frac_majma ) )\n",
    "            medfrac_minma.append( np.median( frac_minma ) )\n",
    "            medfrac_majdiff.append( np.median( frac_majdiff ) )\n",
    "            medfrac_mindiff.append( np.median( frac_mindiff ) )\n",
    "            \n",
    "            quartfrac_majdw.append( np.percentile( frac_majdw, [lower,upper] ) )\n",
    "            quartfrac_mindw.append( np.percentile( frac_mindw, [lower,upper] ) )\n",
    "            quartfrac_majma.append( np.percentile( frac_majma, [lower,upper] ) )\n",
    "            quartfrac_minma.append( np.percentile( frac_minma, [lower,upper] ) )\n",
    "            quartfrac_majdiff.append( np.percentile( frac_majdiff, [lower,upper] ) )\n",
    "            quartfrac_mindiff.append( np.percentile( frac_mindiff, [lower,upper] ) )\n",
    "\n",
    "                                   \n",
    "        except KeyError:\n",
    "            if errorprint: print(f'skipping {snap} for KeyError. Please debug')\n",
    "            continue\n",
    "            \n",
    "        except EmptyFile:\n",
    "            if errorprint: print(f\"skipping {snap}, empty file\")\n",
    "            continue\n",
    "            \n",
    "        except SkipRedshift:\n",
    "            if errorprint: print(f\"skipping {snap}, redshift out of range\")\n",
    "                \n",
    "    count_dictionary = {\n",
    "            \"z\": np.array(redshifts),\n",
    "        \n",
    "            \"Median Major Dwarf\": np.array(medfrac_majdw),\n",
    "            \"Median Minor Dwarf\": np.array(medfrac_mindw),\n",
    "            \"Median Major Massive\": np.array(medfrac_majma),\n",
    "            \"Median Minor Massive\": np.array(medfrac_minma),\n",
    "            \"Median Major Difference\": np.array(medfrac_majdiff),\n",
    "            \"Median Minor Difference\": np.array(medfrac_mindiff),\n",
    "        \n",
    "            \"Quartile Major Dwarf\": np.array(quartfrac_majdw),\n",
    "            \"Quartile Minor Dwarf\": np.array(quartfrac_mindw),\n",
    "            \"Quartile Major Massive\": np.array(quartfrac_majma),\n",
    "            \"Quartile Minor Massive\": np.array(quartfrac_minma),\n",
    "            \"Quartile Major Difference\": np.array(quartfrac_majdiff),\n",
    "            \"Quartile Minor Difference\": np.array(quartfrac_mindiff) }\n",
    "    \n",
    "    return count_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cee7144b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_pairfracdata(reals):\n",
    "    #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}pairfrac.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"Simulation\":\"TNG100-1 (Hydro)\",\n",
    "                      \"1000 Realization - quartile range\":\"0.5-99.5%\"}\n",
    "\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        ratios = get_pairfrac(reals)\n",
    "\n",
    "        for key, val in ratios.items():\n",
    "            val = np.array(val)\n",
    "            dset = f.create_dataset(f'/{reals} Realizations/{key}', \n",
    "                                    shape=val.shape,\n",
    "                                    dtype=val.dtype)\n",
    "            dset[:] = val\n",
    "        print(\"data saved\")        \n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d6bfdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist...\n",
      "creating file\n",
      "file created successfully. adding header...\n",
      "header added successfully\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "make_pairfracdata(10)\n",
    "make_pairfracdata(100)\n",
    "make_pairfracdata(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b31d3",
   "metadata": {},
   "source": [
    "# Sep and Vel evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5db753d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_sepvel(reals, key, scaled=False, errorprint=False, redshiftcutoff=True): \n",
    "    snapshots = np.arange(0,100,1)\n",
    "    snapshots = np.delete(snapshots, np.where(snapshots==48)[0])\n",
    "    redcutoff = 4.2\n",
    "        \n",
    "    redshifts = []  \n",
    "    med_majdw, med_mindw, med_majma, med_minma = [], [], [], []\n",
    "    med_majdiff, med_mindiff, med_ddiff, med_mdiff = [], [], [], []\n",
    "    quart_majdw, quart_mindw, quart_majma, quart_minma = [], [], [], []\n",
    "    quart_majdiff, quart_mindiff, quart_ddiff, quart_mdiff  = [], [], [], []\n",
    "            \n",
    "    for snap in snapshots:  \n",
    "        try:\n",
    "            pair_path = f\"TNG_{snap}_{reals}.hdf5\"\n",
    "            pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "            \n",
    "            if np.size(pair_data) == 0:\n",
    "                raise EmptyFile\n",
    "                \n",
    "            redshift = pair_data['Header'].attrs['Redshift']\n",
    "            \n",
    "            if redshiftcutoff & ( redshift > redcutoff) :\n",
    "                raise SkipRedshift\n",
    "                \n",
    "            if (len(pair_data['pairs'][\"hydro\"]['Group ID']) == 0):    \n",
    "                raise EmptyFile\n",
    "                \n",
    "            pair = pair_data[\"pairs\"][\"hydro\"]\n",
    "            priStell = np.array(pair[\"Sub1 Stellar Mass\"])\n",
    "            secStell = np.array(pair[\"Sub2 Stellar Mass\"])\n",
    "            pairGroups = np.array(pair[\"Group Mass\"])\n",
    "            pairGrRads = np.array(pair[\"Group Radius\"])\n",
    "            pairReals = np.array(pair[\"Realization\"])\n",
    "            seps = np.array(pair[\"Separation\"]) \n",
    "            vels = np.array(pair[\"RelVel\"])\n",
    "                        \n",
    "            majors = (secStell/priStell > 1/4)\n",
    "            minors = (secStell/priStell > 1/10) & (secStell/priStell < 1/4)\n",
    "            pair_lowsep = (seps > 10)\n",
    "            \n",
    "            if key == \"Separation\":\n",
    "                scaleddat = seps / pairGrRads\n",
    "            elif key == \"RelVel\":\n",
    "                G = 4.3009173e4 # in km^2 kpc / (1e10MâŠ™ s^2)\n",
    "                vvir = np.sqrt(G*pairGroups / pairGrRads)\n",
    "                scaleddat = vels / (vvir)  \n",
    "                \n",
    "            if scaled: \n",
    "                dat = scaleddat\n",
    "            elif key == \"Separation\":\n",
    "                dat = seps\n",
    "            elif key == \"RelVel\":\n",
    "                dat = vels\n",
    "            else:\n",
    "                dat = np.array(pairs[key]) \n",
    "            \n",
    "                 ## dwarfs\n",
    "            pair_pri_dwarf = get_primmask(priStell, \"dwarf\")\n",
    "            pair_group_dwarf = get_groupmask(pairGroups, \"dwarf\")\n",
    "            \n",
    "                # defining combined masks \n",
    "            pair_mask_dwarf = pair_pri_dwarf & pair_group_dwarf & pair_lowsep\n",
    "            \n",
    "            ## massive\n",
    "            pair_pri_massive = get_primmask(priStell, \"massive\")\n",
    "            pair_group_massive = get_groupmask(pairGroups, \"massive\")\n",
    "\n",
    "                # defining combined masks \n",
    "            pair_mask_massive = pair_pri_massive & pair_group_massive & pair_lowsep\n",
    "            \n",
    "            real_majdw = []\n",
    "            real_mindw = []\n",
    "            real_majma = []\n",
    "            real_minma = []\n",
    "            real_majdiff = []\n",
    "            real_mindiff = []\n",
    "            real_ddiff = []\n",
    "            real_mdiff = []\n",
    "            \n",
    "            realizations = np.unique( pairReals )\n",
    "\n",
    "            for real in realizations:\n",
    "                pair_real = pairReals == real\n",
    "\n",
    "                mask_majdw = pair_real & pair_mask_dwarf & majors\n",
    "                mask_mindw = pair_real & pair_mask_dwarf & minors\n",
    "                mask_majma = pair_real & pair_mask_massive & majors\n",
    "                mask_minma = pair_real & pair_mask_massive & minors\n",
    "\n",
    "                majdw_xx = np.median( dat[mask_majdw] )\n",
    "                mindw_xx = np.median( dat[mask_mindw] )\n",
    "                majma_xx = np.median( dat[mask_majma] )\n",
    "                minma_xx = np.median( dat[mask_minma] )\n",
    "\n",
    "                real_majdw.append( majdw_xx )\n",
    "                real_mindw.append( mindw_xx )\n",
    "                real_majma.append( majma_xx )\n",
    "                real_minma.append( minma_xx )\n",
    "                real_majdiff.append( majma_xx - majdw_xx)\n",
    "                real_mindiff.append( minma_xx - mindw_xx)\n",
    "                real_ddiff.append( majdw_xx - mindw_xx)\n",
    "                real_mdiff.append( majma_xx - minma_xx)\n",
    "\n",
    "            lower, upper = 16,84         \n",
    "            redshifts.append( redshift )\n",
    "            \n",
    "            med_majdw.append( np.median(real_majdw) )\n",
    "            med_mindw.append( np.median(real_mindw) )\n",
    "            med_majma.append( np.median(real_majma) )\n",
    "            med_minma.append( np.median(real_minma) )\n",
    "            med_majdiff.append( np.median(real_majdiff) )\n",
    "            med_mindiff.append( np.median(real_mindiff) )\n",
    "            med_ddiff.append( np.median(real_ddiff) )\n",
    "            med_mdiff.append( np.median(real_mdiff) )\n",
    "            \n",
    "            quart_majdw.append( np.percentile( real_majdw, [lower,upper] ) )\n",
    "            quart_mindw.append( np.percentile( real_mindw, [lower,upper] ) )\n",
    "            quart_majma.append( np.percentile( real_majma, [lower,upper] ) )\n",
    "            quart_minma.append( np.percentile( real_minma, [lower,upper] ) )\n",
    "            quart_majdiff.append( np.percentile( real_majdiff, [lower,upper] ) )\n",
    "            quart_mindiff.append( np.percentile( real_mindiff, [lower,upper] ) )\n",
    "            quart_ddiff.append( np.percentile( real_ddiff, [lower,upper] ) )\n",
    "            quart_mdiff.append( np.percentile( real_mdiff, [lower,upper] ) )\n",
    "\n",
    "        except KeyError:\n",
    "            if errorprint: print(f'skipping {snap} for KeyError. Please debug')\n",
    "            continue\n",
    "            \n",
    "        except EmptyFile:\n",
    "            if errorprint: print(f\"skipping {snap}, empty file\")\n",
    "            continue\n",
    "            \n",
    "        except SkipRedshift:\n",
    "            if errorprint: print(f\"skipping {snap}, redshift out of range\")\n",
    "                \n",
    "    scaled_dictionary = {\"z\": np.array(redshifts),\n",
    "\n",
    "                        \"Median Major Dwarf\": np.array(med_majdw),\n",
    "                        \"Median Minor Dwarf\": np.array(med_mindw),\n",
    "                        \"Median Major Massive\": np.array(med_majma),\n",
    "                        \"Median Minor Massive\": np.array(med_minma),\n",
    "                        \"Median Major Difference\": np.array(med_majdiff),\n",
    "                        \"Median Minor Difference\": np.array(med_mindiff),\n",
    "                        \"Median Dwarf Difference\": np.array(med_ddiff),\n",
    "                        \"Median Massive Difference\": np.array(med_mdiff),\n",
    "\n",
    "                        \"Quartile Major Dwarf\": np.array(quart_majdw),\n",
    "                        \"Quartile Minor Dwarf\": np.array(quart_mindw),\n",
    "                        \"Quartile Major Massive\": np.array(quart_majma),\n",
    "                        \"Quartile Minor Massive\": np.array(quart_minma),\n",
    "                        \"Quartile Major Difference\": np.array(quart_majdiff),\n",
    "                        \"Quartile Minor Difference\": np.array(quart_mindiff),\n",
    "                        \"Quartile Dwarf Difference\": np.array(quart_ddiff),\n",
    "                        \"Quartile Massive Difference\": np.array(quart_mdiff)}\n",
    "    \n",
    "    return scaled_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b282f927",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_sepveldata(reals):\n",
    "        #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}sepvel.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"1000 Reals - Quartile Range\":\"16-84%\",\n",
    "                       \"Simulation\":\"TNG100-1 (Hydro)\"}\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        pairs = [(\"Separation\",True),(\"Separation\",False),(\"RelVel\", True),(\"RelVel\", False)]\n",
    "        labels = [\"Scaled Separation\", \"Separation\", \"Scaled Velocity\", \"Velocity\"]         \n",
    "        \n",
    "        for pa, la in zip(pairs, labels):\n",
    "            datums = get_sepvel(reals, pa[0], scaled=pa[1])\n",
    "            print(f\"collected data for {pa}\")\n",
    "\n",
    "            for key, val in datums.items():\n",
    "                val = np.array(val)\n",
    "                dset = f.create_dataset(f'/{reals} Realizations/{la}/{key}', \n",
    "                                        shape=val.shape,\n",
    "                                        dtype=val.dtype)\n",
    "                dset[:] = val\n",
    "                \n",
    "        f.close()\n",
    "        print(\"data saved~\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90391e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "testt = get_sepvel(10, \"RelVel\", scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f653bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': array([4.17683491e+00, 4.00794511e+00, 3.70877426e+00, 3.49086137e+00,\n",
       "        3.28303306e+00, 3.00813107e+00, 2.89578501e+00, 2.73314262e+00,\n",
       "        2.57729027e+00, 2.44422570e+00, 2.31611074e+00, 2.20792547e+00,\n",
       "        2.10326965e+00, 2.00202814e+00, 1.90408954e+00, 1.82268925e+00,\n",
       "        1.74357057e+00, 1.66666956e+00, 1.60423452e+00, 1.53123903e+00,\n",
       "        1.49551217e+00, 1.41409822e+00, 1.35757667e+00, 1.30237846e+00,\n",
       "        1.24847261e+00, 1.20625808e+00, 1.15460271e+00, 1.11415056e+00,\n",
       "        1.03551045e+00, 9.97294226e-01, 9.50531352e-01, 9.23000816e-01,\n",
       "        8.86896938e-01, 8.51470901e-01, 8.16709979e-01, 7.91068249e-01,\n",
       "        7.57441373e-01, 7.32636182e-01, 7.00106354e-01, 6.76110411e-01,\n",
       "        6.44641841e-01, 6.21428745e-01, 5.98543288e-01, 5.75980845e-01,\n",
       "        5.46392183e-01, 5.24565820e-01, 5.03047523e-01, 4.81832943e-01,\n",
       "        4.60917794e-01, 4.40297849e-01, 4.19968942e-01, 3.99926965e-01,\n",
       "        3.80167867e-01, 3.60687657e-01, 3.47853842e-01, 3.28829724e-01,\n",
       "        3.10074120e-01, 2.97717685e-01, 2.73353347e-01, 2.61343256e-01,\n",
       "        2.43540182e-01, 2.25988386e-01, 2.14425036e-01, 1.97284182e-01,\n",
       "        1.80385262e-01, 1.69252033e-01, 1.52748769e-01, 1.41876204e-01,\n",
       "        1.25759332e-01, 1.09869940e-01, 9.94018026e-02, 8.38844308e-02,\n",
       "        7.36613847e-02, 5.85073228e-02, 4.85236300e-02, 3.37243719e-02,\n",
       "        2.39744284e-02, 9.52166697e-03, 2.22044605e-16]),\n",
       " 'Median Major Dwarf': array([0.9254787 , 0.93540494, 0.93941698, 0.94308915, 0.93301704,\n",
       "        0.92613181, 0.92101482, 0.93739663, 0.93152668, 0.94951754,\n",
       "        0.94079564, 0.93871554, 0.94129485, 0.93367309, 0.9289169 ,\n",
       "        0.94703669, 0.9452253 , 0.95096106, 0.95420197, 0.95159431,\n",
       "        0.95277576, 0.95895944, 0.96398618, 0.95657041, 0.9534966 ,\n",
       "        0.96058514, 0.97200099, 0.95550394, 0.98429242, 0.97912147,\n",
       "        0.98470878, 0.97348225, 0.97461468, 0.97484696, 0.97045563,\n",
       "        0.98134677, 0.98128955, 0.97686143, 0.9795615 , 0.9844879 ,\n",
       "        0.98429878, 0.98565975, 0.98437143, 0.9746511 , 0.98325474,\n",
       "        0.99162061, 1.0081725 , 0.99937286, 0.99700584, 1.0111572 ,\n",
       "        1.00172866, 1.01724183, 1.01918859, 1.03202734, 1.01603781,\n",
       "        1.03574289, 1.04038278, 1.02927347, 1.03891162, 1.03905673,\n",
       "        1.04711245, 1.04034215, 1.04740731, 1.04100026, 1.03648241,\n",
       "        1.04067927, 1.06341977, 1.0417773 , 1.04419291, 1.0652563 ,\n",
       "        1.06596963, 1.07183186, 1.06904604, 1.06580587, 1.07294498,\n",
       "        1.05285028, 1.04874196, 1.05327292, 1.05178114]),\n",
       " 'Median Minor Dwarf': array([0.97047325, 0.96615265, 0.96532901, 0.96671057, 0.96593146,\n",
       "        0.95695889, 0.96096624, 0.96592355, 0.97213061, 0.97846155,\n",
       "        0.97775402, 0.97969448, 0.97413888, 0.98568483, 0.97842519,\n",
       "        0.97720871, 0.97603021, 0.98212536, 0.99777206, 0.9934085 ,\n",
       "        0.99208987, 0.98430574, 0.99369538, 1.00784081, 0.99196562,\n",
       "        0.99544969, 0.99715818, 0.99954671, 1.01349392, 1.01408523,\n",
       "        1.01892564, 1.01437787, 1.02336059, 1.02373231, 1.02041448,\n",
       "        1.02167877, 1.01796211, 1.01385054, 1.02260146, 1.01994587,\n",
       "        1.03050688, 1.02999116, 1.02915492, 1.0315232 , 1.04097176,\n",
       "        1.03834911, 1.04235334, 1.0364131 , 1.02434657, 1.03394148,\n",
       "        1.04729028, 1.05374847, 1.04778036, 1.05388246, 1.06397072,\n",
       "        1.05701927, 1.07392849, 1.06095138, 1.07095486, 1.05606359,\n",
       "        1.08253901, 1.06512222, 1.06764277, 1.05950479, 1.06051826,\n",
       "        1.05871461, 1.06491236, 1.0693706 , 1.05716278, 1.05942869,\n",
       "        1.07347446, 1.07948638, 1.08659156, 1.08241997, 1.08541524,\n",
       "        1.07364901, 1.07446629, 1.08734496, 1.0700971 ]),\n",
       " 'Median Major Massive': array([0.8098234 , 0.90671073, 0.9325616 , 0.88833832, 0.95314959,\n",
       "        0.91475308, 0.87571447, 0.8935147 , 0.87015848, 0.92079233,\n",
       "        0.92376465, 0.89123209, 0.95023165, 0.94792777, 0.93346296,\n",
       "        0.95258677, 0.96114035, 0.97225297, 0.97381528, 0.96224707,\n",
       "        0.97772114, 0.9936117 , 0.95734588, 0.97299833, 0.97327384,\n",
       "        0.98303647, 0.93700248, 0.97215595, 1.0115427 , 0.99768306,\n",
       "        1.00721485, 1.00019135, 1.00040619, 0.98370031, 0.99309587,\n",
       "        0.99822055, 0.99735258, 1.00740803, 1.00380823, 0.98909898,\n",
       "        0.98046316, 0.98494603, 0.9931509 , 1.01068028, 1.01266538,\n",
       "        0.99713541, 1.02868476, 1.02258332, 0.99878129, 0.97198394,\n",
       "        0.98771767, 0.98654044, 1.00170412, 1.01876008, 1.03989837,\n",
       "        1.02587349, 1.0428901 , 1.01663186, 1.00505988, 1.01009163,\n",
       "        1.00255252, 1.01541778, 1.03504548, 1.03574951, 1.06693319,\n",
       "        1.07973091, 1.07576263, 1.08038074, 1.06995237, 1.06560248,\n",
       "        1.06615603, 1.03663188, 1.04486023, 1.04082629, 1.04837246,\n",
       "        1.04481657, 1.03343519, 1.0383459 , 1.04336543]),\n",
       " 'Median Minor Massive': array([0.92032294, 0.95590851, 0.99214883, 0.97524816, 0.98052505,\n",
       "        0.95756888, 0.95802882, 0.96922645, 0.99910142, 1.01742059,\n",
       "        0.98711584, 0.97124745, 1.02256643, 0.99394149, 1.00318703,\n",
       "        0.98301767, 1.00917166, 1.03496172, 1.01389454, 1.01465958,\n",
       "        1.0314645 , 1.02983088, 1.02034167, 1.02686858, 1.00158331,\n",
       "        1.02093122, 1.0118297 , 0.99774601, 1.027411  , 1.05035513,\n",
       "        0.999554  , 1.04428022, 0.98432953, 0.97737209, 1.02197401,\n",
       "        1.02723316, 1.02217785, 1.04103543, 1.01800828, 1.04376596,\n",
       "        1.04327256, 1.01908544, 1.02149788, 1.01606191, 1.03306071,\n",
       "        1.02047902, 1.01920915, 1.01213942, 1.00961916, 1.0115138 ,\n",
       "        1.00422989, 1.00277796, 1.02075345, 1.0220276 , 1.03454235,\n",
       "        1.02375257, 1.04626329, 1.03009829, 1.03348443, 1.01346522,\n",
       "        1.05918867, 1.06073488, 1.07541955, 1.08396527, 1.06894373,\n",
       "        1.08128881, 1.07037436, 1.05069958, 1.0331936 , 1.03854068,\n",
       "        1.03599708, 1.03351382, 1.05061304, 1.03776449, 1.05181758,\n",
       "        1.05422241, 1.08777767, 1.03674218, 1.04510274]),\n",
       " 'Median Major Difference': array([-9.42663929e-02, -3.71752971e-02,  1.72522535e-03, -5.51252775e-02,\n",
       "         2.09874165e-02, -8.75870104e-03, -3.03901555e-02, -4.02106848e-02,\n",
       "        -5.90407958e-02, -2.00447314e-02, -2.04427872e-02, -3.50432376e-02,\n",
       "         7.33066133e-03,  1.82970471e-02,  4.99137052e-03,  6.33278883e-03,\n",
       "         1.56910173e-02,  3.05535911e-02,  1.99806547e-02,  1.62639766e-02,\n",
       "         2.90077466e-02,  3.55026941e-02,  6.01931049e-03,  2.23365497e-02,\n",
       "         2.39887104e-02,  2.39907336e-02, -3.36794125e-02,  2.14473824e-02,\n",
       "         3.28213389e-02,  2.18468668e-02,  2.75677861e-02,  3.08505621e-02,\n",
       "         1.86455251e-02,  1.55598536e-02,  2.31705728e-02,  1.98730861e-02,\n",
       "         2.37157769e-02,  3.72648190e-02,  1.82906019e-02,  4.54410069e-04,\n",
       "         1.30468574e-03,  4.15591059e-03, -3.95456107e-05,  3.52902600e-02,\n",
       "         2.85935271e-02,  6.05193915e-03,  1.85184054e-02,  2.35082376e-02,\n",
       "         2.23083947e-03, -3.03554728e-02, -1.10332059e-02, -2.76453765e-02,\n",
       "        -1.71661454e-02, -1.57228169e-02,  2.60756458e-02, -9.19902909e-03,\n",
       "         1.86554690e-03, -1.05129458e-02, -3.22198440e-02, -2.99469931e-02,\n",
       "        -4.40948409e-02, -2.73983737e-02, -1.17319279e-02, -3.45793041e-03,\n",
       "         2.45285481e-02,  4.25607540e-02,  1.07121264e-02,  3.88683861e-02,\n",
       "         3.05520737e-02,  2.64408724e-03,  1.01998618e-02, -4.09296015e-02,\n",
       "        -2.64197048e-02, -2.58884632e-02, -3.17874787e-02, -7.99845903e-03,\n",
       "        -1.70042523e-02, -1.36755096e-02, -1.03835241e-02]),\n",
       " 'Median Minor Difference': array([-0.05866203,  0.00144707,  0.02575113,  0.00925319,  0.01571594,\n",
       "        -0.00385347,  0.00266647,  0.00827235,  0.02752211,  0.03630889,\n",
       "         0.01227006, -0.0012828 ,  0.04695441,  0.00209824,  0.02271867,\n",
       "         0.0093921 ,  0.02539696,  0.04983476,  0.01526236,  0.02506955,\n",
       "         0.04119312,  0.03777069,  0.02212908,  0.0170717 ,  0.00300363,\n",
       "         0.03428526,  0.0183207 , -0.00893452,  0.00883321,  0.03774911,\n",
       "        -0.01293973,  0.02763629, -0.03454527, -0.04743134,  0.01629744,\n",
       "         0.00077144,  0.00183699,  0.02195433, -0.00324228,  0.02866367,\n",
       "         0.00156883, -0.01307731, -0.00618932, -0.01542138, -0.00498017,\n",
       "        -0.02308364, -0.0241013 , -0.02839872, -0.01536908, -0.02135796,\n",
       "        -0.04260581, -0.05252987, -0.020303  , -0.02927093, -0.03977278,\n",
       "        -0.03204801, -0.02001934, -0.04088083, -0.04151419, -0.04274956,\n",
       "        -0.01968802, -0.00488723,  0.00754193,  0.03515488,  0.01355988,\n",
       "         0.0235772 , -0.00111001, -0.01990307, -0.01916139, -0.01244584,\n",
       "        -0.0403288 , -0.03138646, -0.02485271, -0.02915406, -0.0347966 ,\n",
       "        -0.03126691,  0.01015261, -0.04269249, -0.01930318]),\n",
       " 'Median Dwarf Difference': array([-0.04270893, -0.02617675, -0.0328153 , -0.02449687, -0.0333506 ,\n",
       "        -0.03250305, -0.04271655, -0.03224732, -0.04183878, -0.02628399,\n",
       "        -0.04046182, -0.04986   , -0.03403967, -0.04909126, -0.04946715,\n",
       "        -0.02717301, -0.03692225, -0.03647931, -0.0445731 , -0.04366038,\n",
       "        -0.03927613, -0.02002631, -0.03231273, -0.05121959, -0.03797522,\n",
       "        -0.03741376, -0.02961733, -0.04867071, -0.02735344, -0.03762841,\n",
       "        -0.03551918, -0.03967092, -0.04273486, -0.04813939, -0.04905911,\n",
       "        -0.04930616, -0.04482605, -0.04229246, -0.0405462 , -0.0344361 ,\n",
       "        -0.04878587, -0.04231567, -0.04368084, -0.05110918, -0.05922973,\n",
       "        -0.04327026, -0.02671595, -0.03371901, -0.02401581, -0.02793389,\n",
       "        -0.04590067, -0.0397949 , -0.02788132, -0.02449025, -0.05160478,\n",
       "        -0.02127638, -0.02858927, -0.02445429, -0.03031774, -0.01169102,\n",
       "        -0.0340542 , -0.02235442, -0.01831143, -0.020878  , -0.02458077,\n",
       "        -0.01953235,  0.00337289, -0.01153896, -0.01631603, -0.00501099,\n",
       "        -0.00907544, -0.00666079, -0.0086173 , -0.0140625 , -0.01098838,\n",
       "        -0.02230583, -0.01595959, -0.0330034 , -0.01646   ]),\n",
       " 'Median Massive Difference': array([-0.10113074, -0.11052369, -0.0853406 , -0.08384228, -0.02577112,\n",
       "        -0.0468604 , -0.07215367, -0.07503339, -0.13242137, -0.07751872,\n",
       "        -0.06038651, -0.08764502, -0.07216853, -0.04343077, -0.06445416,\n",
       "        -0.0389368 , -0.04703996, -0.060532  , -0.04105188, -0.04865018,\n",
       "        -0.05174698, -0.04327113, -0.05348008, -0.05921986, -0.03808515,\n",
       "        -0.03643432, -0.07669357, -0.03044048, -0.01153647, -0.05420336,\n",
       "         0.01185977, -0.03548569,  0.00083391,  0.00919026, -0.03985379,\n",
       "        -0.03791019, -0.01658222, -0.03331858, -0.01476997, -0.05449907,\n",
       "        -0.05784452, -0.03407004, -0.02707855, -0.00400611, -0.01847194,\n",
       "        -0.02701838,  0.00347572,  0.0101884 , -0.00955184, -0.04010806,\n",
       "        -0.01396221, -0.01546255, -0.01466353, -0.00840026,  0.0020763 ,\n",
       "         0.00126687, -0.01211332, -0.01030598, -0.02453187, -0.00419866,\n",
       "        -0.04895905, -0.04126594, -0.04127887, -0.06040683, -0.00875236,\n",
       "         0.00278252,  0.01501833,  0.03131171,  0.03645276,  0.01954186,\n",
       "         0.0226459 , -0.0129275 , -0.00953072,  0.00844172, -0.01373927,\n",
       "        -0.01500407, -0.05597055,  0.00263166, -0.00235997]),\n",
       " 'Quartile Major Dwarf': array([[0.91931012, 0.9415395 ],\n",
       "        [0.92165084, 0.95277795],\n",
       "        [0.92045343, 0.94676278],\n",
       "        [0.93487256, 0.95797739],\n",
       "        [0.92200377, 0.94603261],\n",
       "        [0.91915533, 0.93613992],\n",
       "        [0.9148604 , 0.93122052],\n",
       "        [0.9294933 , 0.94644131],\n",
       "        [0.92090758, 0.93911603],\n",
       "        [0.9392767 , 0.95551317],\n",
       "        [0.93314562, 0.94634316],\n",
       "        [0.92754025, 0.94434729],\n",
       "        [0.93504767, 0.95086543],\n",
       "        [0.92748061, 0.94670294],\n",
       "        [0.92131947, 0.93722439],\n",
       "        [0.93274963, 0.95700384],\n",
       "        [0.93301353, 0.95030772],\n",
       "        [0.94051511, 0.95772824],\n",
       "        [0.94585139, 0.96181736],\n",
       "        [0.94363022, 0.95530152],\n",
       "        [0.94360484, 0.96751964],\n",
       "        [0.9524345 , 0.96994634],\n",
       "        [0.94920078, 0.96653086],\n",
       "        [0.94313161, 0.96307034],\n",
       "        [0.94028651, 0.96183894],\n",
       "        [0.94592091, 0.96987896],\n",
       "        [0.96404809, 0.97873912],\n",
       "        [0.94027461, 0.96326152],\n",
       "        [0.98061489, 0.98925745],\n",
       "        [0.9685246 , 0.98211981],\n",
       "        [0.97612686, 0.9918794 ],\n",
       "        [0.9631633 , 0.98402563],\n",
       "        [0.96100266, 0.98553094],\n",
       "        [0.9643433 , 0.98249666],\n",
       "        [0.96339728, 0.98789636],\n",
       "        [0.96613012, 0.98741299],\n",
       "        [0.96795191, 0.98505249],\n",
       "        [0.96440876, 0.98559154],\n",
       "        [0.97155722, 0.9981713 ],\n",
       "        [0.97339361, 0.99237842],\n",
       "        [0.96443468, 0.98947842],\n",
       "        [0.96724736, 1.00138087],\n",
       "        [0.97842863, 0.99042951],\n",
       "        [0.96390133, 0.98620158],\n",
       "        [0.9791898 , 0.98443668],\n",
       "        [0.97994726, 1.00020515],\n",
       "        [0.98313764, 1.01477093],\n",
       "        [0.99479735, 1.0101848 ],\n",
       "        [0.98822522, 1.00533758],\n",
       "        [0.9939216 , 1.01816001],\n",
       "        [0.99416477, 1.00928138],\n",
       "        [1.0068579 , 1.02451507],\n",
       "        [1.01379443, 1.02936172],\n",
       "        [1.02698283, 1.03750962],\n",
       "        [1.0057641 , 1.02224116],\n",
       "        [1.02092682, 1.04513742],\n",
       "        [1.0279244 , 1.04795779],\n",
       "        [1.01677854, 1.04580573],\n",
       "        [1.02833524, 1.04915192],\n",
       "        [1.02633845, 1.04320703],\n",
       "        [1.04365951, 1.063524  ],\n",
       "        [1.03157704, 1.05324343],\n",
       "        [1.03936852, 1.05291426],\n",
       "        [1.02666635, 1.05479104],\n",
       "        [1.03251088, 1.05362121],\n",
       "        [1.02709816, 1.04894268],\n",
       "        [1.04422399, 1.07644421],\n",
       "        [1.01931925, 1.06887359],\n",
       "        [1.03292229, 1.05946772],\n",
       "        [1.04601701, 1.06794108],\n",
       "        [1.04785093, 1.0758379 ],\n",
       "        [1.06309672, 1.07797092],\n",
       "        [1.05893381, 1.08252704],\n",
       "        [1.05412179, 1.08257495],\n",
       "        [1.05927811, 1.09394473],\n",
       "        [1.0455176 , 1.06197672],\n",
       "        [1.04028546, 1.06384364],\n",
       "        [1.04674854, 1.06445285],\n",
       "        [1.04259667, 1.06364266]]),\n",
       " 'Quartile Minor Dwarf': array([[0.95110542, 0.9791693 ],\n",
       "        [0.93646915, 0.97722562],\n",
       "        [0.95095017, 0.97814611],\n",
       "        [0.96123528, 0.98003894],\n",
       "        [0.95779573, 0.9755681 ],\n",
       "        [0.94906132, 0.97352152],\n",
       "        [0.95535695, 0.97407376],\n",
       "        [0.95942975, 0.98455505],\n",
       "        [0.95949953, 0.97634006],\n",
       "        [0.96675928, 0.99175538],\n",
       "        [0.97063224, 0.9876684 ],\n",
       "        [0.96333914, 0.99713442],\n",
       "        [0.96989915, 0.98074498],\n",
       "        [0.97176537, 0.99010212],\n",
       "        [0.9703078 , 0.98475625],\n",
       "        [0.96233293, 0.99385829],\n",
       "        [0.96697186, 0.98887322],\n",
       "        [0.97981907, 0.99179113],\n",
       "        [0.9892948 , 1.00465087],\n",
       "        [0.98218549, 1.00902604],\n",
       "        [0.98302703, 1.0053715 ],\n",
       "        [0.97439217, 1.00269086],\n",
       "        [0.98660098, 1.01028181],\n",
       "        [0.99863396, 1.01017478],\n",
       "        [0.98423585, 0.99755677],\n",
       "        [0.97955258, 1.00260458],\n",
       "        [0.98754155, 1.00414066],\n",
       "        [0.99533687, 1.01227612],\n",
       "        [1.00200828, 1.03150266],\n",
       "        [0.9960494 , 1.02533655],\n",
       "        [1.00233734, 1.03768119],\n",
       "        [0.99938322, 1.03378164],\n",
       "        [1.01228689, 1.03790266],\n",
       "        [1.01542151, 1.03683681],\n",
       "        [0.99817175, 1.02770703],\n",
       "        [1.0140964 , 1.03362009],\n",
       "        [1.00870769, 1.0278607 ],\n",
       "        [1.00682205, 1.02668577],\n",
       "        [1.01371542, 1.03511367],\n",
       "        [1.00489314, 1.03525236],\n",
       "        [1.02175397, 1.0521988 ],\n",
       "        [1.01604893, 1.04243391],\n",
       "        [1.01523557, 1.03508715],\n",
       "        [1.02315658, 1.04957592],\n",
       "        [1.03453146, 1.05682586],\n",
       "        [1.02138133, 1.05450491],\n",
       "        [1.0230978 , 1.05362622],\n",
       "        [1.01941779, 1.04485155],\n",
       "        [1.01281607, 1.04287236],\n",
       "        [1.02848275, 1.04344064],\n",
       "        [1.03801947, 1.05565885],\n",
       "        [1.03811585, 1.06503874],\n",
       "        [1.03623017, 1.06727229],\n",
       "        [1.03890815, 1.07371678],\n",
       "        [1.05374734, 1.0786367 ],\n",
       "        [1.04573268, 1.07584543],\n",
       "        [1.05930513, 1.07764095],\n",
       "        [1.0526611 , 1.08047437],\n",
       "        [1.0681747 , 1.08732731],\n",
       "        [1.03970518, 1.07220433],\n",
       "        [1.05640024, 1.08895852],\n",
       "        [1.05332172, 1.07340786],\n",
       "        [1.05395625, 1.0735154 ],\n",
       "        [1.04138701, 1.07434012],\n",
       "        [1.04483616, 1.086617  ],\n",
       "        [1.05120898, 1.07514398],\n",
       "        [1.04823472, 1.07506784],\n",
       "        [1.05110872, 1.08628487],\n",
       "        [1.04118172, 1.06612542],\n",
       "        [1.0486336 , 1.07870502],\n",
       "        [1.05379794, 1.09118054],\n",
       "        [1.06267286, 1.08146962],\n",
       "        [1.07287976, 1.0971844 ],\n",
       "        [1.05940738, 1.0912296 ],\n",
       "        [1.05572967, 1.09814174],\n",
       "        [1.06290519, 1.09893143],\n",
       "        [1.04935187, 1.08459326],\n",
       "        [1.05816648, 1.10086059],\n",
       "        [1.04505543, 1.08480034]]),\n",
       " 'Quartile Major Massive': array([[0.78893468, 0.87585168],\n",
       "        [0.82607211, 0.9523099 ],\n",
       "        [0.8391018 , 0.96398529],\n",
       "        [0.87943019, 0.91270491],\n",
       "        [0.89451015, 0.98471317],\n",
       "        [0.90232674, 0.92066896],\n",
       "        [0.8537351 , 0.94764075],\n",
       "        [0.88574156, 0.9156948 ],\n",
       "        [0.83958432, 0.88996463],\n",
       "        [0.90421605, 0.96864839],\n",
       "        [0.90021354, 0.93757946],\n",
       "        [0.86616231, 0.92407916],\n",
       "        [0.9286933 , 0.95528083],\n",
       "        [0.93265053, 0.9607575 ],\n",
       "        [0.91882764, 0.95345698],\n",
       "        [0.93478682, 0.9593723 ],\n",
       "        [0.94606047, 0.96760989],\n",
       "        [0.94980302, 0.99146837],\n",
       "        [0.96400878, 0.98218521],\n",
       "        [0.94654628, 0.97923317],\n",
       "        [0.96146109, 0.9893176 ],\n",
       "        [0.9666398 , 1.00781338],\n",
       "        [0.95521732, 0.98109613],\n",
       "        [0.95899769, 0.98419091],\n",
       "        [0.95060289, 0.98033413],\n",
       "        [0.94526895, 1.00101076],\n",
       "        [0.92350525, 0.94747781],\n",
       "        [0.95640653, 0.98375103],\n",
       "        [0.99917787, 1.03037163],\n",
       "        [0.98026059, 1.01454725],\n",
       "        [0.98860294, 1.02708208],\n",
       "        [0.99265811, 1.0102653 ],\n",
       "        [0.96938703, 1.00769093],\n",
       "        [0.97697989, 0.99661277],\n",
       "        [0.97476531, 1.00336324],\n",
       "        [0.98638276, 1.0157471 ],\n",
       "        [0.99530532, 1.00759377],\n",
       "        [1.00334063, 1.0162541 ],\n",
       "        [0.98670134, 1.01410772],\n",
       "        [0.96877608, 1.00041031],\n",
       "        [0.96750831, 0.98978766],\n",
       "        [0.97831777, 0.99825855],\n",
       "        [0.97432238, 1.00457862],\n",
       "        [1.00347184, 1.01715087],\n",
       "        [0.99761894, 1.02755526],\n",
       "        [0.97956375, 1.01035274],\n",
       "        [1.01596051, 1.033771  ],\n",
       "        [1.01628049, 1.03220847],\n",
       "        [0.99450019, 1.00916054],\n",
       "        [0.96726292, 0.98999237],\n",
       "        [0.98265375, 0.99662805],\n",
       "        [0.98054958, 0.99856275],\n",
       "        [0.99834521, 1.01256094],\n",
       "        [1.00669357, 1.02384572],\n",
       "        [1.02957084, 1.05616212],\n",
       "        [1.01276304, 1.03333286],\n",
       "        [1.02828929, 1.04890326],\n",
       "        [1.00931221, 1.03311268],\n",
       "        [0.99307599, 1.01251128],\n",
       "        [0.99837595, 1.02459735],\n",
       "        [0.99945399, 1.01590026],\n",
       "        [0.99865593, 1.02563829],\n",
       "        [1.02517719, 1.04075883],\n",
       "        [1.02736664, 1.05464755],\n",
       "        [1.05736939, 1.0718428 ],\n",
       "        [1.0716862 , 1.08872541],\n",
       "        [1.0595309 , 1.08726439],\n",
       "        [1.06644307, 1.09111345],\n",
       "        [1.06677526, 1.07258069],\n",
       "        [1.05642885, 1.07046577],\n",
       "        [1.0596504 , 1.078737  ],\n",
       "        [1.01357485, 1.04064921],\n",
       "        [1.03566295, 1.05921801],\n",
       "        [1.02961575, 1.06052074],\n",
       "        [1.03517061, 1.05802697],\n",
       "        [1.03649608, 1.04821289],\n",
       "        [1.02860389, 1.04157184],\n",
       "        [1.03721928, 1.04688252],\n",
       "        [1.0377129 , 1.0490051 ]]),\n",
       " 'Quartile Minor Massive': array([[0.87617054, 0.96981518],\n",
       "        [0.91653226, 1.02798554],\n",
       "        [0.95435102, 1.02619691],\n",
       "        [0.93861907, 1.01934035],\n",
       "        [0.95327838, 1.01317223],\n",
       "        [0.92085828, 0.98763975],\n",
       "        [0.94298   , 0.9722857 ],\n",
       "        [0.93492968, 1.00686358],\n",
       "        [0.9715381 , 1.01416476],\n",
       "        [0.98394286, 1.04248296],\n",
       "        [0.98016772, 1.00811033],\n",
       "        [0.95394801, 0.98840941],\n",
       "        [0.99512384, 1.05414765],\n",
       "        [0.96754142, 0.99919208],\n",
       "        [0.98527749, 1.0093098 ],\n",
       "        [0.96532584, 1.02398285],\n",
       "        [0.993645  , 1.01892903],\n",
       "        [1.01089068, 1.04273365],\n",
       "        [0.98902967, 1.02385924],\n",
       "        [0.99264581, 1.03397339],\n",
       "        [1.00912   , 1.0447363 ],\n",
       "        [0.99670796, 1.0457149 ],\n",
       "        [1.00781003, 1.03560933],\n",
       "        [1.0036644 , 1.04492701],\n",
       "        [0.98743613, 1.02779986],\n",
       "        [0.99406602, 1.05239852],\n",
       "        [1.00009249, 1.02472382],\n",
       "        [0.98296508, 1.0146529 ],\n",
       "        [1.0101794 , 1.04074049],\n",
       "        [1.02814998, 1.06829514],\n",
       "        [0.98516094, 1.02622386],\n",
       "        [1.02216769, 1.05948929],\n",
       "        [0.96095059, 1.0253639 ],\n",
       "        [0.9448131 , 1.01335283],\n",
       "        [0.99713507, 1.04018679],\n",
       "        [0.97217266, 1.04403146],\n",
       "        [0.9998673 , 1.0503096 ],\n",
       "        [1.02699549, 1.05270919],\n",
       "        [0.99901671, 1.05368146],\n",
       "        [1.03177816, 1.05191881],\n",
       "        [1.02061054, 1.06543777],\n",
       "        [0.99462248, 1.03637017],\n",
       "        [0.99975653, 1.04542381],\n",
       "        [1.00872818, 1.02937604],\n",
       "        [1.0103874 , 1.04582885],\n",
       "        [0.9873317 , 1.04183981],\n",
       "        [1.00587583, 1.03750892],\n",
       "        [0.98678898, 1.04053861],\n",
       "        [0.99782958, 1.02633918],\n",
       "        [0.9857828 , 1.02446619],\n",
       "        [0.98055845, 1.02491197],\n",
       "        [0.98573504, 1.01697909],\n",
       "        [0.99704039, 1.04004511],\n",
       "        [1.00160341, 1.03342501],\n",
       "        [0.99203925, 1.06652431],\n",
       "        [0.98393223, 1.05910591],\n",
       "        [1.02113305, 1.07551997],\n",
       "        [0.99131548, 1.04755725],\n",
       "        [1.01975415, 1.0448684 ],\n",
       "        [0.98731536, 1.04787266],\n",
       "        [1.03877964, 1.06760486],\n",
       "        [1.03405115, 1.07726504],\n",
       "        [1.05541548, 1.08702271],\n",
       "        [1.07259696, 1.11042338],\n",
       "        [1.04552051, 1.0916179 ],\n",
       "        [1.03827097, 1.09535321],\n",
       "        [1.02417603, 1.08219978],\n",
       "        [1.02866383, 1.06943073],\n",
       "        [1.01914316, 1.04504382],\n",
       "        [1.00148419, 1.06406511],\n",
       "        [1.02361658, 1.05221522],\n",
       "        [1.02432931, 1.05110381],\n",
       "        [1.03895878, 1.08712905],\n",
       "        [1.02871908, 1.08281112],\n",
       "        [1.03924164, 1.08113998],\n",
       "        [1.03168298, 1.08154942],\n",
       "        [1.04153756, 1.09515486],\n",
       "        [1.02344712, 1.05750071],\n",
       "        [1.02798598, 1.05833741]]),\n",
       " 'Quartile Major Difference': array([[-0.14197451, -0.05196818],\n",
       "        [-0.09380244,  0.0156423 ],\n",
       "        [-0.08873213,  0.02343091],\n",
       "        [-0.06594438, -0.00951505],\n",
       "        [-0.03386563,  0.05490682],\n",
       "        [-0.02609311, -0.00119238],\n",
       "        [-0.05785829,  0.01296209],\n",
       "        [-0.05686579, -0.0141812 ],\n",
       "        [-0.07946299, -0.02320733],\n",
       "        [-0.04270519,  0.02427529],\n",
       "        [-0.03637186,  0.00288085],\n",
       "        [-0.07278482, -0.01075599],\n",
       "        [-0.01782759,  0.03204279],\n",
       "        [ 0.00772838,  0.02718667],\n",
       "        [-0.00454754,  0.0278948 ],\n",
       "        [-0.01388081,  0.02085758],\n",
       "        [ 0.00738269,  0.03242082],\n",
       "        [ 0.00057087,  0.04755894],\n",
       "        [ 0.00486994,  0.04517527],\n",
       "        [-0.0103194 ,  0.03871739],\n",
       "        [ 0.01333055,  0.04174738],\n",
       "        [ 0.00684036,  0.04892317],\n",
       "        [-0.00934663,  0.03891722],\n",
       "        [-0.00443783,  0.03596711],\n",
       "        [ 0.00677165,  0.02876017],\n",
       "        [-0.0062924 ,  0.04257912],\n",
       "        [-0.0440082 , -0.02301435],\n",
       "        [ 0.0103992 ,  0.0339712 ],\n",
       "        [ 0.01248087,  0.04951835],\n",
       "        [ 0.00730336,  0.04602264],\n",
       "        [-0.00099429,  0.04617264],\n",
       "        [ 0.00800161,  0.04647743],\n",
       "        [ 0.00114734,  0.04755603],\n",
       "        [-0.00410929,  0.02511712],\n",
       "        [-0.00815004,  0.05465018],\n",
       "        [ 0.00510974,  0.03992469],\n",
       "        [ 0.01272256,  0.03786032],\n",
       "        [ 0.01968754,  0.04484076],\n",
       "        [ 0.003649  ,  0.04543931],\n",
       "        [-0.00763108,  0.01898396],\n",
       "        [-0.01018193,  0.01015351],\n",
       "        [-0.01558514,  0.01645802],\n",
       "        [-0.00651577,  0.02494184],\n",
       "        [ 0.02373594,  0.05216266],\n",
       "        [ 0.01466484,  0.04684441],\n",
       "        [-0.01934875,  0.03007487],\n",
       "        [ 0.01054874,  0.05450899],\n",
       "        [-0.00272515,  0.0344683 ],\n",
       "        [-0.00184333,  0.01794447],\n",
       "        [-0.05416178, -0.00853977],\n",
       "        [-0.02685196, -0.00404111],\n",
       "        [-0.03273424, -0.01278568],\n",
       "        [-0.02927565, -0.00184307],\n",
       "        [-0.02707288, -0.0036815 ],\n",
       "        [ 0.01046897,  0.04615268],\n",
       "        [-0.0234331 ,  0.01240605],\n",
       "        [-0.01572721,  0.01557594],\n",
       "        [-0.02442455,  0.00338233],\n",
       "        [-0.05428316, -0.02098907],\n",
       "        [-0.03793324, -0.01381311],\n",
       "        [-0.06087324, -0.03075446],\n",
       "        [-0.04300045, -0.01402827],\n",
       "        [-0.02073679, -0.00396101],\n",
       "        [-0.01519351,  0.00922947],\n",
       "        [ 0.01068923,  0.03422857],\n",
       "        [ 0.02536152,  0.05543028],\n",
       "        [-0.00427957,  0.02762678],\n",
       "        [ 0.00176035,  0.05706615],\n",
       "        [ 0.00401425,  0.03647414],\n",
       "        [-0.01108206,  0.01450674],\n",
       "        [-0.01155367,  0.01761863],\n",
       "        [-0.05773083, -0.02389292],\n",
       "        [-0.04139094, -0.00804801],\n",
       "        [-0.04285037,  0.0146651 ],\n",
       "        [-0.05133019, -0.00694916],\n",
       "        [-0.01621973, -0.00499357],\n",
       "        [-0.03033856,  0.00050237],\n",
       "        [-0.02626532, -0.00129857],\n",
       "        [-0.02425304,  0.00271269]]),\n",
       " 'Quartile Minor Difference': array([[-8.80694068e-02,  3.21284456e-02],\n",
       "        [-5.05588970e-02,  6.34925491e-02],\n",
       "        [-2.30991978e-02,  6.19767438e-02],\n",
       "        [-3.77668012e-02,  5.22330258e-02],\n",
       "        [-1.71546338e-02,  4.79451322e-02],\n",
       "        [-3.31296053e-02,  2.46656310e-02],\n",
       "        [-2.57618457e-02,  1.62597720e-02],\n",
       "        [-2.82899857e-02,  2.61724159e-02],\n",
       "        [ 3.76408285e-04,  4.62634401e-02],\n",
       "        [ 1.55235409e-05,  6.62987359e-02],\n",
       "        [-5.91938059e-03,  3.71608326e-02],\n",
       "        [-3.09757346e-02,  1.28979066e-02],\n",
       "        [ 3.33352524e-02,  7.37162759e-02],\n",
       "        [-1.02326736e-02,  2.16789345e-02],\n",
       "        [ 4.42215982e-03,  3.94121341e-02],\n",
       "        [-1.29814173e-02,  3.17698293e-02],\n",
       "        [ 1.98621278e-02,  3.64074803e-02],\n",
       "        [ 2.85272437e-02,  5.63718673e-02],\n",
       "        [-3.85816732e-03,  2.85613526e-02],\n",
       "        [ 1.36038748e-03,  4.38852724e-02],\n",
       "        [ 3.06165927e-03,  5.53370986e-02],\n",
       "        [ 1.60107840e-02,  6.25563407e-02],\n",
       "        [ 1.28982949e-02,  4.00229899e-02],\n",
       "        [-5.09060968e-03,  3.95457465e-02],\n",
       "        [-4.88013010e-03,  3.04944435e-02],\n",
       "        [-7.71768908e-03,  6.12119808e-02],\n",
       "        [ 1.92733016e-03,  2.23584895e-02],\n",
       "        [-2.47309792e-02,  3.02326094e-02],\n",
       "        [-1.26966889e-02,  2.79496544e-02],\n",
       "        [ 1.71014230e-02,  5.95150795e-02],\n",
       "        [-3.04185200e-02, -3.43936726e-05],\n",
       "        [-2.76952771e-03,  5.20429637e-02],\n",
       "        [-5.75035834e-02, -2.30467204e-03],\n",
       "        [-8.44856990e-02, -8.75427608e-03],\n",
       "        [-2.55403814e-02,  2.61676474e-02],\n",
       "        [-5.26892866e-02,  2.37211887e-02],\n",
       "        [-2.09509740e-02,  2.77451869e-02],\n",
       "        [ 1.14664377e-02,  3.94769682e-02],\n",
       "        [-2.51083916e-02,  2.20320388e-02],\n",
       "        [-1.26097457e-02,  4.03671114e-02],\n",
       "        [-2.22497820e-02,  4.07863831e-02],\n",
       "        [-3.61206217e-02,  6.33564598e-03],\n",
       "        [-2.94588534e-02,  1.82843607e-02],\n",
       "        [-3.04983036e-02,  1.78216081e-03],\n",
       "        [-4.25540041e-02,  8.12240161e-03],\n",
       "        [-5.06334880e-02, -1.17760409e-03],\n",
       "        [-4.30975282e-02, -2.85269469e-03],\n",
       "        [-5.12398877e-02,  1.03612835e-02],\n",
       "        [-3.00626399e-02,  8.70681246e-03],\n",
       "        [-5.42231795e-02,  2.23675703e-04],\n",
       "        [-7.04039647e-02, -1.55168895e-02],\n",
       "        [-6.81736302e-02, -3.14181328e-02],\n",
       "        [-6.53975455e-02, -7.46509588e-03],\n",
       "        [-6.47988936e-02, -1.44195379e-02],\n",
       "        [-7.24282335e-02, -2.12043890e-03],\n",
       "        [-5.86989923e-02, -5.17953937e-03],\n",
       "        [-4.34007027e-02,  1.79162279e-03],\n",
       "        [-6.39978863e-02, -1.33499880e-02],\n",
       "        [-5.49840694e-02, -3.02245539e-02],\n",
       "        [-7.77633745e-02, -7.04240258e-03],\n",
       "        [-4.49425794e-02,  1.06973770e-02],\n",
       "        [-1.75649658e-02,  1.11652578e-02],\n",
       "        [-1.33601416e-02,  2.57699420e-02],\n",
       "        [ 1.07743907e-02,  4.85939316e-02],\n",
       "        [-1.38774614e-02,  3.35454114e-02],\n",
       "        [-1.61146021e-02,  3.72971622e-02],\n",
       "        [-4.17975353e-02,  2.72407823e-02],\n",
       "        [-3.86590540e-02,  2.00308498e-02],\n",
       "        [-4.75958588e-02, -9.14080712e-03],\n",
       "        [-6.64405185e-02,  1.52654069e-04],\n",
       "        [-5.41690091e-02, -1.25760307e-02],\n",
       "        [-5.60390491e-02, -2.07533856e-02],\n",
       "        [-6.06881220e-02,  2.38264186e-03],\n",
       "        [-5.50315105e-02,  1.16559140e-02],\n",
       "        [-4.88481770e-02,  2.52031943e-02],\n",
       "        [-6.20443453e-02,  1.64355510e-02],\n",
       "        [-3.33050604e-02,  3.28133691e-02],\n",
       "        [-7.96002358e-02, -1.39021552e-02],\n",
       "        [-3.86779858e-02, -5.37522404e-04]]),\n",
       " 'Quartile Dwarf Difference': array([[-0.05130963, -0.02482136],\n",
       "        [-0.04872322, -0.01153888],\n",
       "        [-0.051447  , -0.0117743 ],\n",
       "        [-0.04580666, -0.01114083],\n",
       "        [-0.06083016, -0.01797449],\n",
       "        [-0.0518958 , -0.02083803],\n",
       "        [-0.05627532, -0.0234711 ],\n",
       "        [-0.06267321, -0.0141407 ],\n",
       "        [-0.05139102, -0.02550277],\n",
       "        [-0.04640838, -0.0198446 ],\n",
       "        [-0.04985634, -0.02516704],\n",
       "        [-0.0614429 , -0.01806655],\n",
       "        [-0.0417402 , -0.01904218],\n",
       "        [-0.0683869 , -0.03032819],\n",
       "        [-0.06037488, -0.03404925],\n",
       "        [-0.06108115, -0.0118763 ],\n",
       "        [-0.04527786, -0.01985354],\n",
       "        [-0.04465143, -0.02539392],\n",
       "        [-0.05378331, -0.02723442],\n",
       "        [-0.0611047 , -0.028777  ],\n",
       "        [-0.05186675, -0.02314691],\n",
       "        [-0.04472387, -0.008078  ],\n",
       "        [-0.05423068, -0.02370305],\n",
       "        [-0.06272047, -0.03955124],\n",
       "        [-0.05376345, -0.02642992],\n",
       "        [-0.04669843, -0.01980472],\n",
       "        [-0.03551547, -0.00646256],\n",
       "        [-0.06714478, -0.03193633],\n",
       "        [-0.04746762, -0.01455786],\n",
       "        [-0.05282988, -0.02018112],\n",
       "        [-0.05210466, -0.01443078],\n",
       "        [-0.05786365, -0.02779214],\n",
       "        [-0.0769    , -0.03328118],\n",
       "        [-0.06910679, -0.03776318],\n",
       "        [-0.06119365, -0.01716878],\n",
       "        [-0.05563875, -0.02886851],\n",
       "        [-0.05242259, -0.02512843],\n",
       "        [-0.05014347, -0.02707905],\n",
       "        [-0.06117839, -0.01965061],\n",
       "        [-0.05846392, -0.0166876 ],\n",
       "        [-0.07297163, -0.03313296],\n",
       "        [-0.06845193, -0.02401692],\n",
       "        [-0.05338708, -0.01944434],\n",
       "        [-0.08567459, -0.0399551 ],\n",
       "        [-0.07113098, -0.05207276],\n",
       "        [-0.06435789, -0.02712201],\n",
       "        [-0.06455586, -0.01497033],\n",
       "        [-0.04478459, -0.0215117 ],\n",
       "        [-0.05163067, -0.00674704],\n",
       "        [-0.04371558, -0.0165678 ],\n",
       "        [-0.05745913, -0.02794091],\n",
       "        [-0.05375728, -0.01360078],\n",
       "        [-0.05974372, -0.00515479],\n",
       "        [-0.04395644,  0.00082605],\n",
       "        [-0.07698198, -0.02352839],\n",
       "        [-0.04654339,  0.00209539],\n",
       "        [-0.04621553, -0.01448287],\n",
       "        [-0.06240028, -0.00764814],\n",
       "        [-0.05521383, -0.02013753],\n",
       "        [-0.04613995, -0.00262711],\n",
       "        [-0.04684887,  0.00599446],\n",
       "        [-0.03597922, -0.00805094],\n",
       "        [-0.0333228 , -0.00724468],\n",
       "        [-0.03682489,  0.01541105],\n",
       "        [-0.04622393,  0.01012774],\n",
       "        [-0.04465322, -0.00203857],\n",
       "        [-0.01584373,  0.01416961],\n",
       "        [-0.06542823,  0.01343506],\n",
       "        [-0.03033522,  0.01830888],\n",
       "        [-0.01630043,  0.01835286],\n",
       "        [-0.03731109,  0.01332371],\n",
       "        [-0.01617024,  0.00129286],\n",
       "        [-0.03606457,  0.00715052],\n",
       "        [-0.02832292,  0.00786384],\n",
       "        [-0.02946018,  0.03127947],\n",
       "        [-0.04711101, -0.00069138],\n",
       "        [-0.03998214, -0.00374949],\n",
       "        [-0.05066168, -0.00628749],\n",
       "        [-0.03302865,  0.0084849 ]]),\n",
       " 'Quartile Massive Difference': array([[-1.77850963e-01,  2.68941627e-03],\n",
       "        [-1.60197315e-01,  2.79466879e-02],\n",
       "        [-1.58816935e-01,  1.76104086e-03],\n",
       "        [-1.31750138e-01, -1.78415792e-02],\n",
       "        [-9.14604104e-02,  1.47503099e-03],\n",
       "        [-8.54991237e-02, -7.25503295e-03],\n",
       "        [-1.15645596e-01, -6.30003200e-03],\n",
       "        [-1.21427574e-01, -3.38517833e-02],\n",
       "        [-1.62126781e-01, -6.50461596e-02],\n",
       "        [-1.10387427e-01, -5.62721414e-02],\n",
       "        [-1.02687801e-01, -5.18995257e-02],\n",
       "        [-1.08154888e-01, -3.82211120e-02],\n",
       "        [-9.63585976e-02, -4.11240921e-02],\n",
       "        [-6.02382613e-02, -1.63487881e-02],\n",
       "        [-8.89694630e-02, -4.63078896e-02],\n",
       "        [-8.45074524e-02,  2.15392371e-03],\n",
       "        [-6.70693146e-02, -2.35607409e-02],\n",
       "        [-8.66589931e-02, -3.60253910e-02],\n",
       "        [-5.73281501e-02, -6.15224048e-03],\n",
       "        [-7.19926809e-02, -2.85407326e-02],\n",
       "        [-7.85571348e-02, -3.36860773e-02],\n",
       "        [-6.72938254e-02,  1.11054160e-02],\n",
       "        [-7.47230381e-02, -3.59531592e-02],\n",
       "        [-7.77034578e-02, -2.31833028e-02],\n",
       "        [-6.00342635e-02, -4.77813534e-03],\n",
       "        [-8.58860298e-02, -7.70523274e-03],\n",
       "        [-9.29889370e-02, -5.36410294e-02],\n",
       "        [-5.32419212e-02, -1.12291161e-02],\n",
       "        [-3.94838946e-02,  1.43967854e-02],\n",
       "        [-7.18342439e-02, -2.74296658e-02],\n",
       "        [-2.78640188e-02,  3.78989425e-02],\n",
       "        [-6.59705970e-02, -1.35363701e-02],\n",
       "        [-1.96831284e-02,  4.53460897e-02],\n",
       "        [-3.52747570e-02,  5.54699622e-02],\n",
       "        [-5.93956318e-02, -9.56177474e-04],\n",
       "        [-5.31777706e-02,  3.80557360e-02],\n",
       "        [-5.43534089e-02,  3.42652765e-04],\n",
       "        [-4.55703488e-02, -8.80796881e-03],\n",
       "        [-5.55507338e-02,  1.20123038e-02],\n",
       "        [-7.55351699e-02, -3.74153311e-02],\n",
       "        [-9.81194549e-02, -3.30938306e-02],\n",
       "        [-5.14134373e-02, -8.59247826e-03],\n",
       "        [-5.91555422e-02, -1.34394161e-02],\n",
       "        [-2.28346021e-02,  3.48533799e-03],\n",
       "        [-4.14364255e-02,  6.85772802e-03],\n",
       "        [-5.56319367e-02,  1.90136179e-02],\n",
       "        [-1.53494248e-02,  3.20321160e-02],\n",
       "        [-1.97123107e-02,  4.07270402e-02],\n",
       "        [-2.97187829e-02,  9.66043549e-03],\n",
       "        [-6.06821833e-02, -1.59747405e-04],\n",
       "        [-4.22795378e-02,  4.76983862e-03],\n",
       "        [-2.85326785e-02,  3.64276346e-03],\n",
       "        [-4.88918377e-02,  1.57407641e-02],\n",
       "        [-2.28059654e-02,  1.78600804e-02],\n",
       "        [-2.67240897e-02,  5.57926979e-02],\n",
       "        [-4.46870801e-02,  4.66803853e-02],\n",
       "        [-2.89330622e-02,  1.95066186e-02],\n",
       "        [-4.14439029e-02,  4.12741281e-02],\n",
       "        [-6.29826554e-02, -8.42037747e-03],\n",
       "        [-5.20329752e-02,  2.82490705e-02],\n",
       "        [-6.67010622e-02, -1.87344443e-02],\n",
       "        [-6.94208965e-02, -7.66199459e-03],\n",
       "        [-5.69835302e-02, -1.70122253e-02],\n",
       "        [-7.20134572e-02, -2.32195234e-02],\n",
       "        [-2.44750089e-02,  1.63200020e-02],\n",
       "        [-1.75775655e-02,  4.42392022e-02],\n",
       "        [-2.57926012e-02,  4.89513499e-02],\n",
       "        [-7.63567652e-03,  5.91039560e-02],\n",
       "        [ 2.32767476e-02,  5.24550641e-02],\n",
       "        [ 5.06571059e-03,  6.50896898e-02],\n",
       "        [ 1.57029616e-02,  5.50157560e-02],\n",
       "        [-3.51489789e-02,  1.81126858e-02],\n",
       "        [-5.30373880e-02,  1.84305349e-02],\n",
       "        [-5.31953713e-02,  2.38463996e-02],\n",
       "        [-3.25475708e-02,  1.12990168e-02],\n",
       "        [-3.31130145e-02,  1.50161970e-02],\n",
       "        [-6.30577264e-02, -6.03236207e-05],\n",
       "        [-1.21772836e-02,  1.64354579e-02],\n",
       "        [-1.86297783e-02,  1.96572406e-02]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c07ba6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist...\n",
      "creating file\n",
      "file created successfully. adding header...\n",
      "header added successfully\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "collected data for ('Separation', True)\n",
      "collected data for ('Separation', False)\n",
      "collected data for ('RelVel', True)\n",
      "collected data for ('RelVel', False)\n",
      "data saved~\n"
     ]
    }
   ],
   "source": [
    "make_sepveldata(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c7d18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(f\"{paths.path_plotdata}sepvel.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d946f677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.15031387,  3.71732223,  5.71879622,  4.88309816,  6.28992762,\n",
       "        5.8165457 ,  5.76829513,  5.31830854,  5.73811704,  6.75990854,\n",
       "        6.34658907,  6.02112966,  7.15618795,  4.95292941,  5.55306841,\n",
       "        6.88886272,  6.21601593,  5.92606282,  7.38699145,  8.14420185,\n",
       "        8.44984178,  9.1258511 ,  8.2024838 ,  6.12870759,  6.59343332,\n",
       "        7.2594458 ,  8.61704835,  4.23817197,  7.64768501,  8.9518017 ,\n",
       "       13.28410105,  7.8299432 ,  9.217027  ,  6.26384857,  8.67960261,\n",
       "        9.40885956, 10.24419211, 10.53082664,  9.63321497, 10.4976103 ,\n",
       "       10.81600759, 10.41915926, 11.54586645, 14.13942388, 10.49593869,\n",
       "       13.28054761, 12.96761123, 15.10727725, 13.20898145, 16.90326564,\n",
       "        7.42979832, 10.35968554, 12.74512643, 14.90441467,  9.17277696,\n",
       "       11.66414272, 12.72597282, 13.11785777, 10.45486323, 11.58677574,\n",
       "       16.34838903, 12.86980491, 16.88520207, 14.2942911 , 17.93946417,\n",
       "        7.49535382, 14.86295338, 14.97533294, 13.49400196, 23.94937646,\n",
       "       27.9406779 , 26.14203637, 20.36135634, 16.61259503, 13.10184673,\n",
       "       18.81415877, 20.6402675 , 24.27065362, 17.70053866])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(f['10 Realizations'][\"Separation\"][\"Median Dwarf Difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8cbe5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009664a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmake_sepveldata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m make_sepveldata(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      3\u001b[0m make_sepveldata(\u001b[38;5;241m1000\u001b[39m)\n",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m, in \u001b[0;36mmake_sepveldata\u001b[0;34m(reals)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_sepveldata\u001b[39m(reals):\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;66;03m#check if files exists\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpaths\u001b[38;5;241m.\u001b[39mpath_plotdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124msepvel.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile does not exist...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "make_sepveldata(10)\n",
    "make_sepveldata(100)\n",
    "make_sepveldata(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "081eac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(f\"{paths.path_plotdata}sepvel.hdf5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "554ac45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['10 Realizations', '100 Realizations', '1000 Realizations', 'Header']>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "901d8c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['Median Major Difference', 'Median Major Dwarf', 'Median Major Massive', 'Median Minor Difference', 'Median Minor Dwarf', 'Median Minor Massive', 'Quartile Major Difference', 'Quartile Major Dwarf', 'Quartile Major Massive', 'Quartile Minor Difference', 'Quartile Minor Dwarf', 'Quartile Minor Massive', 'z']>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[\"100 Realizations\"][\"Separation\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42808767",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560afb0",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16819a42",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_sepveldist(reals, size, key, z, scaled=False):\n",
    "    zloc = np.where( zs['z'] == z)[0]\n",
    "    sim = \"TNG\"\n",
    "    snapshot = zs['ztng'][zloc][0] \n",
    "\n",
    "    pair_path = f\"{sim}_{snapshot}_{reals}.hdf5\"\n",
    "    pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "    \n",
    "    pairs = pair_data[\"pairs\"][\"hydro\"]\n",
    "\n",
    "    pri_stell = np.array(pairs[\"Sub1 Stellar Mass\"])\n",
    "    sec_stell = np.array(pairs[\"Sub2 Stellar Mass\"])\n",
    "    pairGroups = np.array(pairs[\"Group Mass\"])\n",
    "    pairGrRads = np.array(pairs[\"Group Radius\"])\n",
    "    seps = np.array(pairs[\"Separation\"]) \n",
    "    vels = np.array(pairs[\"RelVel\"]) \n",
    "    \n",
    "    # masks            \n",
    "    pair_pri = get_primmask(pri_stell, size)\n",
    "    pair_group = get_groupmask(pairGroups, size)\n",
    "    pair_sepcut = seps > 10\n",
    "    \n",
    "    pair_mask = pair_pri & pair_group & pair_sepcut\n",
    "    \n",
    "    majors = (sec_stell/pri_stell > 1/4)\n",
    "    minors = (sec_stell/pri_stell > 1/10) & (sec_stell/pri_stell < 1/4)\n",
    "\n",
    "    major_mask = pair_mask & majors\n",
    "    minor_mask = pair_mask & minors\n",
    "    \n",
    "    if key == \"Separation\":\n",
    "        scaleddat = seps / pairGrRads\n",
    "    elif key == \"RelVel\":\n",
    "        G = 4.3009173e4 # in km^2 kpc / (1e10MâŠ™ s^2)\n",
    "        vvir = np.sqrt(G*pairGroups / pairGrRads)\n",
    "        scaleddat = vels / (vvir)    \n",
    "    \n",
    "    if scaled: \n",
    "        dat = scaleddat\n",
    "    elif key == \"Separation\":\n",
    "        dat = seps\n",
    "    elif key == \"RelVel\":\n",
    "        dat = vels\n",
    "    else:\n",
    "        dat = np.array(pairs[key]) \n",
    "\n",
    "    majors = dat[major_mask]\n",
    "    minors = dat[minor_mask]\n",
    "\n",
    "    key_dict = {\"major\":majors, \"minor\":minors}\n",
    "    \n",
    "\n",
    "    return key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494becfa",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_sepveldistdata(reals):\n",
    "        #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}sepveldist.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"1000 Reals - Quartile Range\":\"16-84%\",\n",
    "                       \"Simulation\":\"TNG100-1 (Hydro)\"}\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        labels = [\"Scaled Separation\", \"Separation\", \"Scaled Velocity\", \"Velocity\"]         \n",
    "        \n",
    "        for z in zs[\"z\"]:\n",
    "            for size in [\"dwarf\",\"massive\"]:\n",
    "                ssep = get_sepveldist(reals, size, \"Separation\", z, scaled=True)\n",
    "                sep = get_sepveldist(reals, size, \"Separation\", z, scaled=False)\n",
    "                svel = get_sepveldist(reals, size, \"RelVel\", z, scaled=True)\n",
    "                vel = get_sepveldist(reals, size, \"RelVel\", z, scaled=False)\n",
    "              \n",
    "                for datt, labb in zip([ssep,sep,svel,vel],labels):\n",
    "                    for key, val in datt.items():\n",
    "                        val = np.array(val)\n",
    "                        dset = f.create_dataset(f'/{reals} Realizations/z={z}/{size}/{labb}/{key}', \n",
    "                                                shape=val.shape,\n",
    "                                                dtype=val.dtype)\n",
    "                        dset[:] = val\n",
    "                    \n",
    "            print(f\"finished z={z}\")        \n",
    "                        \n",
    "        f.close()\n",
    "        print(\"data saved~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ff5cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist...\n",
      "creating file\n",
      "file created successfully. adding header...\n",
      "header added successfully\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved~\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved~\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "finished z=0\n",
      "finished z=1\n",
      "finished z=2\n",
      "finished z=3\n",
      "finished z=4\n",
      "data saved~\n"
     ]
    }
   ],
   "source": [
    "make_sepveldistdata(10)\n",
    "make_sepveldistdata(100)\n",
    "make_sepveldistdata(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a15ff9",
   "metadata": {},
   "source": [
    "# Separation cuts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91061d0",
   "metadata": {},
   "source": [
    "**by physical distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a835782",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_pairfrac_sepcut(reals, sepcut, errorprint=False, redshiftcutoff=True):    \n",
    "    snapshots = np.arange(0,100,1)\n",
    "    snapshots = np.delete(snapshots, np.where(snapshots==48)[0])\n",
    "    redcutoff = 4.2\n",
    "        \n",
    "    redshifts = []\n",
    "    medfrac_majdw_cut, medfrac_mindw_cut, medfrac_majma_cut, medfrac_minma_cut  = [], [], [], []\n",
    "    quartfrac_majdw_cut, quartfrac_mindw_cut, quartfrac_majma_cut, quartfrac_minma_cut = [], [], [], []\n",
    "    medfrac_majdw_recovered, medfrac_mindw_recovered, medfrac_majma_recovered, medfrac_minma_recovered  = [], [], [], []\n",
    "    quartfrac_majdw_recovered, quartfrac_mindw_recovered, quartfrac_majma_recovered, quartfrac_minma_recovered = [], [], [], []\n",
    "\n",
    "    for snap in snapshots:  \n",
    "        frac_majdw_cut, frac_mindw_cut, frac_majma_cut, frac_minma_cut = [], [], [], []\n",
    "        frac_majdw_recovered, frac_mindw_recovered, frac_majma_recovered, frac_minma_recovered = [], [], [], []\n",
    "        \n",
    "        try:\n",
    "            pair_path = f\"TNG_{snap}_{reals}.hdf5\"\n",
    "            pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "            \n",
    "            if np.size(pair_data) == 0:\n",
    "                raise EmptyFile\n",
    "                \n",
    "            redshift = pair_data['Header'].attrs['Redshift']\n",
    "            \n",
    "            if redshiftcutoff & ( redshift > redcutoff) :\n",
    "                raise SkipRedshift\n",
    "                \n",
    "            if (len(pair_data['pairs'][\"hydro\"]['Group ID']) == 0):    \n",
    "                raise EmptyFile\n",
    "            \n",
    "            # unpaired masks\n",
    "            unpair = pair_data[\"unpaired\"][\"hydro\"]\n",
    "            unpairStells = np.array(unpair[\"Sub1 Stellar Mass\"])\n",
    "            unpairGroups = np.array(unpair[\"Group Mass\"])\n",
    "            unpairReals = np.array(unpair['Realization'])\n",
    "            \n",
    "                ## unpaired dwarf primaries and groups\n",
    "            unpair_pri_dwarf = get_primmask(unpairStells, \"dwarf\")\n",
    "            unpair_group_dwarf = get_groupmask(unpairGroups, \"dwarf\")      \n",
    "            \n",
    "                ## unpaired massive primaries and groups\n",
    "            unpair_pri_massive = get_primmask(unpairStells, \"massive\")\n",
    "            unpair_group_massive = get_groupmask(unpairGroups, \"massive\")   \n",
    "            \n",
    "            # paired masks\n",
    "            pair = pair_data[\"pairs\"][\"hydro\"]\n",
    "            priStell = np.array(pair[\"Sub1 Stellar Mass\"])\n",
    "            secStell = np.array(pair[\"Sub2 Stellar Mass\"])\n",
    "            pairGroups = np.array(pair[\"Group Mass\"])\n",
    "            pairReals = np.array(pair[\"Realization\"])\n",
    "            \n",
    "                ## paired dwarf primaries and groups\n",
    "            pair_pri_dwarf = get_primmask(priStell, \"dwarf\")\n",
    "            pair_group_dwarf = get_groupmask(pairGroups, \"dwarf\")\n",
    "            \n",
    "                ## paired massive primaries and groups\n",
    "            pair_pri_massive = get_primmask(priStell, \"massive\")\n",
    "            pair_group_massive = get_groupmask(pairGroups, \"massive\")\n",
    "            \n",
    "            # major/minor pair masks\n",
    "            majors = (secStell/priStell > 1/4)\n",
    "            minors = (secStell/priStell > 1/10) & (secStell/priStell < 1/4)\n",
    "            allpairs = (majors + minors)\n",
    "            \n",
    "            # sep pair mask\n",
    "            seps = np.array(pair[\"Separation\"]) \n",
    "            pair_lowsep = (seps > 10)\n",
    "            pair_highsep = (seps < sepcut)\n",
    "            \n",
    "                ## dwarf primaries and pairs ~ \n",
    "            unpair_mask_dwarf = unpair_pri_dwarf & unpair_group_dwarf\n",
    "            primary_mask_dwarf = pair_pri_dwarf & pair_group_dwarf            \n",
    "            pair_mask_dwarf = pair_pri_dwarf & pair_group_dwarf & pair_lowsep & allpairs\n",
    "            pair_mask_dwarf_cut = pair_mask_dwarf & pair_highsep\n",
    "            \n",
    "                # massive primaries and pairs\n",
    "            unpair_mask_massive = unpair_pri_massive & unpair_group_massive\n",
    "            primary_mask_massive = pair_pri_massive & pair_group_massive\n",
    "            pair_mask_massive = pair_pri_massive & pair_group_massive & pair_lowsep  & allpairs\n",
    "            pair_mask_massive_cut = pair_mask_massive & pair_highsep\n",
    "                                                          \n",
    "            for real in np.unique(unpairReals):                  \n",
    "                # make realization masks\n",
    "                unpair_real = unpairReals == real\n",
    "                pair_real = pairReals == real\n",
    "\n",
    "                # make count values for single realization\n",
    "                numone_dwarf = np.count_nonzero(unpair_mask_dwarf & unpair_real)\n",
    "                numtwo_dwarf = np.count_nonzero(primary_mask_dwarf & pair_real)\n",
    "                numtot_dwarf = numone_dwarf + numtwo_dwarf\n",
    "                nummaj_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & majors)\n",
    "                nummin_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & minors)\n",
    "                numpair_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real)\n",
    "                    # cut numbers\n",
    "                nummaj_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real & majors)\n",
    "                nummin_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real & minors)\n",
    "                numpair_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real)\n",
    "\n",
    "                \n",
    "                \n",
    "                # make count values for single realization\n",
    "                numone_massive = np.count_nonzero(unpair_mask_massive & unpair_real)\n",
    "                numtwo_massive = np.count_nonzero(primary_mask_massive & pair_real)\n",
    "                numtot_massive = numone_massive + numtwo_massive\n",
    "                nummaj_massive = np.count_nonzero(pair_mask_massive & pair_real & majors)\n",
    "                nummin_massive = np.count_nonzero(pair_mask_massive & pair_real & minors)\n",
    "                numpair_massive = np.count_nonzero(pair_mask_massive & pair_real)\n",
    "                    # cut numbers\n",
    "                nummaj_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real & majors)\n",
    "                nummin_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real & minors)\n",
    "                numpair_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real)\n",
    "                \n",
    "                if (numtot_dwarf == 0) or (numtot_massive == 0):\n",
    "                    continue\n",
    "                    \n",
    "                # collect vals for all reals\n",
    "                frac_majdw_cut.append( nummaj_dwarf_cut/numtot_dwarf ) \n",
    "                frac_mindw_cut.append( nummin_dwarf_cut/numtot_dwarf ) \n",
    "                frac_majma_cut.append( nummaj_massive_cut/numtot_massive ) \n",
    "                frac_minma_cut.append( nummin_massive_cut/numtot_massive ) \n",
    "                \n",
    "                frac_majdw_recovered.append( nummaj_dwarf_cut/nummaj_dwarf )\n",
    "                frac_mindw_recovered.append( nummin_dwarf_cut/nummin_dwarf ) \n",
    "                frac_majma_recovered.append( nummaj_massive_cut/nummaj_massive ) \n",
    "                frac_minma_recovered.append( nummin_massive_cut/nummin_massive ) \n",
    "                \n",
    "                                    \n",
    "            # create arrays of medians and quartiles~ \n",
    "            lower, upper = 0.5, 99.5                \n",
    "            redshifts.append( redshift )\n",
    "            \n",
    "            medfrac_majdw_cut.append( np.median( frac_majdw_cut ) )\n",
    "            medfrac_mindw_cut.append( np.median( frac_mindw_cut ) )\n",
    "            medfrac_majma_cut.append( np.median( frac_majma_cut ) )\n",
    "            medfrac_minma_cut.append( np.median( frac_minma_cut ) )\n",
    "            medfrac_majdw_recovered.append( np.median( frac_majdw_recovered ) )\n",
    "            medfrac_mindw_recovered.append( np.median( frac_mindw_recovered ) )\n",
    "            medfrac_majma_recovered.append( np.median( frac_majma_recovered ) )\n",
    "            medfrac_minma_recovered.append( np.median( frac_minma_recovered ) )\n",
    "            \n",
    "            quartfrac_majdw_cut.append( np.percentile( frac_majdw_cut, [lower,upper] ) )\n",
    "            quartfrac_mindw_cut.append( np.percentile( frac_mindw_cut, [lower,upper] ) )\n",
    "            quartfrac_majma_cut.append( np.percentile( frac_majma_cut, [lower,upper] ) )\n",
    "            quartfrac_minma_cut.append( np.percentile( frac_minma_cut, [lower,upper] ) )\n",
    "            quartfrac_majdw_recovered.append( np.percentile( frac_majdw_recovered, [lower,upper] ) )\n",
    "            quartfrac_mindw_recovered.append( np.percentile( frac_mindw_recovered, [lower,upper] ) )\n",
    "            quartfrac_majma_recovered.append( np.percentile( frac_majma_recovered, [lower,upper] ) )\n",
    "            quartfrac_minma_recovered.append( np.percentile( frac_minma_recovered, [lower,upper] ) )\n",
    "                                   \n",
    "        except KeyError:\n",
    "            if errorprint: print(f'skipping {snap} for KeyError. Please debug')\n",
    "            continue\n",
    "            \n",
    "        except EmptyFile:\n",
    "            if errorprint: print(f\"skipping {snap}, empty file\")\n",
    "            continue\n",
    "            \n",
    "        except SkipRedshift:\n",
    "            if errorprint: print(f\"skipping {snap}, redshift out of range\")\n",
    "                \n",
    "    count_dictionary = {\n",
    "            \"z\": np.array(redshifts),\n",
    "        \n",
    "            \"Median Major Dwarf\": np.array(medfrac_majdw_cut),\n",
    "            \"Median Minor Dwarf\": np.array(medfrac_mindw_cut),\n",
    "            \"Median Major Massive\": np.array(medfrac_majma_cut),\n",
    "            \"Median Minor Massive\": np.array(medfrac_minma_cut),\n",
    "            \"Frac Major Dwarf Recovered\": np.array(medfrac_majdw_recovered),\n",
    "            \"Frac Minor Dwarf Recovered\": np.array(medfrac_mindw_recovered),\n",
    "            \"Frac Major Massive Recovered\": np.array(medfrac_majma_recovered),\n",
    "            \"Frac Minor Massive Recovered\": np.array(medfrac_minma_recovered),\n",
    "        \n",
    "            \"Quartile Major Dwarf\": np.array(quartfrac_majdw_cut),\n",
    "            \"Quartile Minor Dwarf\": np.array(quartfrac_mindw_cut),\n",
    "            \"Quartile Major Massive\": np.array(quartfrac_majma_cut),\n",
    "            \"Quartile Minor Massive\": np.array(quartfrac_minma_cut),\n",
    "            \"Quartile Major Dwarf Recovered\": np.array(quartfrac_majdw_recovered),\n",
    "            \"Quartile Minor Dwarf Recovered\": np.array(quartfrac_mindw_recovered),\n",
    "            \"Quartile Major Massive Recovered\": np.array(quartfrac_majma_recovered),\n",
    "            \"Quartile Minor Massive Recovered\": np.array(quartfrac_minma_recovered)\n",
    "            }\n",
    "    \n",
    "    return count_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "229fc5bc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_pairfracdata_sepcut(reals, sepcut):\n",
    "    #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}pairfrac_sepcut.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"Simulation\":\"TNG100-1 (Hydro)\",\n",
    "                      \"1000 Realization - quartile range\":\"0.5-99.5%\",\n",
    "                      \"Separation Cut\":f\"{sepcut}kpc\"}\n",
    "\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations/Sepcut {sepcut}kpc\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        ratios = get_pairfrac_sepcut(reals,sepcut)\n",
    "\n",
    "        for key, val in ratios.items():\n",
    "            val = np.array(val)\n",
    "            dset = f.create_dataset(f'/{reals} Realizations/Sepcut {sepcut}kpc/{key}', \n",
    "                                    shape=val.shape,\n",
    "                                    dtype=val.dtype)\n",
    "            dset[:] = val\n",
    "        print(\"data saved\")        \n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c628b915",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepcut is: 50\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "sepcut is: 70\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "sepcut is: 100\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "sepcut is: 150\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "sepcut is: 200\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "sepcut is: 300\n",
      "**** starting 10 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "**** starting 100 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "**** starting 1000 ****\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for sepcut in [50, 70, 100, 150, 200, 300]:\n",
    "#     print(f\"sepcut is: {sepcut}\")\n",
    "#     print(\"**** starting 10 ****\")\n",
    "#     make_pairfracdata_sepcut(10,sepcut)\n",
    "    \n",
    "#     print(\"**** starting 100 ****\")\n",
    "#     make_pairfracdata_sepcut(100,sepcut)    \n",
    "    \n",
    "    print(\"**** starting 1000 ****\")\n",
    "    make_pairfracdata_sepcut(1000,sepcut)    \n",
    "    \n",
    "# make_pairfracdata_sepcut(10,50) #\n",
    "# make_pairfracdata_sepcut(10,70) # Snyder 2023\n",
    "# make_pairfracdata_sepcut(10,100) #\n",
    "# make_pairfracdata_sepcut(10,150) # Besla 2018\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e09ae",
   "metadata": {},
   "source": [
    "**by virial radius**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f44020ae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_pairfrac_vircut(reals, vircut, errorprint=False, redshiftcutoff=True):    \n",
    "    snapshots = np.arange(0,100,1)\n",
    "    snapshots = np.delete(snapshots, np.where(snapshots==48)[0])\n",
    "    redcutoff = 4.2\n",
    "        \n",
    "    redshifts = []\n",
    "    medfrac_majdw_cut, medfrac_mindw_cut, medfrac_majma_cut, medfrac_minma_cut  = [], [], [], []\n",
    "    quartfrac_majdw_cut, quartfrac_mindw_cut, quartfrac_majma_cut, quartfrac_minma_cut = [], [], [], []\n",
    "    medfrac_majdw_recovered, medfrac_mindw_recovered, medfrac_majma_recovered, medfrac_minma_recovered  = [], [], [], []\n",
    "    quartfrac_majdw_recovered, quartfrac_mindw_recovered, quartfrac_majma_recovered, quartfrac_minma_recovered = [], [], [], []\n",
    "\n",
    "    for snap in snapshots:  \n",
    "        frac_majdw_cut, frac_mindw_cut, frac_majma_cut, frac_minma_cut = [], [], [], []\n",
    "        frac_majdw_recovered, frac_mindw_recovered, frac_majma_recovered, frac_minma_recovered = [], [], [], []\n",
    "        \n",
    "        try:\n",
    "            pair_path = f\"TNG_{snap}_{reals}.hdf5\"\n",
    "            pair_data = h5py.File(f\"{paths.path_pairs}{pair_path}\", \"r\")\n",
    "            \n",
    "            if np.size(pair_data) == 0:\n",
    "                raise EmptyFile\n",
    "                \n",
    "            redshift = pair_data['Header'].attrs['Redshift']\n",
    "            \n",
    "            if redshiftcutoff & ( redshift > redcutoff) :\n",
    "                raise SkipRedshift\n",
    "                \n",
    "            if (len(pair_data['pairs'][\"hydro\"]['Group ID']) == 0):    \n",
    "                raise EmptyFile\n",
    "            \n",
    "            # unpaired masks\n",
    "            unpair = pair_data[\"unpaired\"][\"hydro\"]\n",
    "            unpairStells = np.array(unpair[\"Sub1 Stellar Mass\"])\n",
    "            unpairGroups = np.array(unpair[\"Group Mass\"])\n",
    "            unpairReals = np.array(unpair['Realization'])\n",
    "            \n",
    "                ## unpaired dwarf primaries and groups\n",
    "            unpair_pri_dwarf = get_primmask(unpairStells, \"dwarf\")\n",
    "            unpair_group_dwarf = get_groupmask(unpairGroups, \"dwarf\")      \n",
    "            \n",
    "                ## unpaired massive primaries and groups\n",
    "            unpair_pri_massive = get_primmask(unpairStells, \"massive\")\n",
    "            unpair_group_massive = get_groupmask(unpairGroups, \"massive\")   \n",
    "            \n",
    "            # paired masks\n",
    "            pair = pair_data[\"pairs\"][\"hydro\"]\n",
    "            priStell = np.array(pair[\"Sub1 Stellar Mass\"])\n",
    "            secStell = np.array(pair[\"Sub2 Stellar Mass\"])\n",
    "            pairGroups = np.array(pair[\"Group Mass\"])\n",
    "            pairRads = np.array(pair[\"Group Radius\"])\n",
    "            pairReals = np.array(pair[\"Realization\"])\n",
    "            \n",
    "                ## paired dwarf primaries and groups\n",
    "            pair_pri_dwarf = get_primmask(priStell, \"dwarf\")\n",
    "            pair_group_dwarf = get_groupmask(pairGroups, \"dwarf\")\n",
    "            \n",
    "                ## paired massive primaries and groups\n",
    "            pair_pri_massive = get_primmask(priStell, \"massive\")\n",
    "            pair_group_massive = get_groupmask(pairGroups, \"massive\")\n",
    "            \n",
    "            # major/minor pair masks\n",
    "            majors = (secStell/priStell > 1/4)\n",
    "            minors = (secStell/priStell > 1/10) & (secStell/priStell < 1/4)\n",
    "            allpairs = (majors + minors)\n",
    "            \n",
    "            # sep pair mask\n",
    "            seps = np.array(pair[\"Separation\"]) \n",
    "            pair_lowsep = (seps > 10)\n",
    "            pair_highsep = (seps < vircut*pairRads)\n",
    "            \n",
    "                ## dwarf primaries and pairs ~ \n",
    "            unpair_mask_dwarf = unpair_pri_dwarf & unpair_group_dwarf\n",
    "            primary_mask_dwarf = pair_pri_dwarf & pair_group_dwarf            \n",
    "            pair_mask_dwarf = pair_pri_dwarf & pair_group_dwarf & pair_lowsep & allpairs\n",
    "            pair_mask_dwarf_cut = pair_mask_dwarf & pair_highsep\n",
    "            \n",
    "                # massive primaries and pairs\n",
    "            unpair_mask_massive = unpair_pri_massive & unpair_group_massive\n",
    "            primary_mask_massive = pair_pri_massive & pair_group_massive\n",
    "            pair_mask_massive = pair_pri_massive & pair_group_massive & pair_lowsep  & allpairs\n",
    "            pair_mask_massive_cut = pair_mask_massive & pair_highsep\n",
    "                                                          \n",
    "            for real in np.unique(unpairReals):                  \n",
    "                # make realization masks\n",
    "                unpair_real = unpairReals == real\n",
    "                pair_real = pairReals == real\n",
    "\n",
    "                # make count values for single realization\n",
    "                numone_dwarf = np.count_nonzero(unpair_mask_dwarf & unpair_real)\n",
    "                numtwo_dwarf = np.count_nonzero(primary_mask_dwarf & pair_real)\n",
    "                numtot_dwarf = numone_dwarf + numtwo_dwarf\n",
    "                nummaj_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & majors)\n",
    "                nummin_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real & minors)\n",
    "                numpair_dwarf = np.count_nonzero(pair_mask_dwarf & pair_real)\n",
    "                    # cut numbers\n",
    "                nummaj_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real & majors)\n",
    "                nummin_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real & minors)\n",
    "                numpair_dwarf_cut = np.count_nonzero(pair_mask_dwarf_cut & pair_real)\n",
    "\n",
    "                \n",
    "                \n",
    "                # make count values for single realization\n",
    "                numone_massive = np.count_nonzero(unpair_mask_massive & unpair_real)\n",
    "                numtwo_massive = np.count_nonzero(primary_mask_massive & pair_real)\n",
    "                numtot_massive = numone_massive + numtwo_massive\n",
    "                nummaj_massive = np.count_nonzero(pair_mask_massive & pair_real & majors)\n",
    "                nummin_massive = np.count_nonzero(pair_mask_massive & pair_real & minors)\n",
    "                numpair_massive = np.count_nonzero(pair_mask_massive & pair_real)\n",
    "                    # cut numbers\n",
    "                nummaj_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real & majors)\n",
    "                nummin_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real & minors)\n",
    "                numpair_massive_cut = np.count_nonzero(pair_mask_massive_cut & pair_real)\n",
    "                \n",
    "                if (numtot_dwarf == 0) or (numtot_massive == 0):\n",
    "                    continue\n",
    "                    \n",
    "                # collect vals for all reals\n",
    "                frac_majdw_cut.append( nummaj_dwarf_cut/numtot_dwarf ) \n",
    "                frac_mindw_cut.append( nummin_dwarf_cut/numtot_dwarf ) \n",
    "                frac_majma_cut.append( nummaj_massive_cut/numtot_massive ) \n",
    "                frac_minma_cut.append( nummin_massive_cut/numtot_massive ) \n",
    "                \n",
    "                frac_majdw_recovered.append( nummaj_dwarf_cut/nummaj_dwarf )\n",
    "                frac_mindw_recovered.append( nummin_dwarf_cut/nummin_dwarf ) \n",
    "                frac_majma_recovered.append( nummaj_massive_cut/nummaj_massive ) \n",
    "                frac_minma_recovered.append( nummin_massive_cut/nummin_massive ) \n",
    "                \n",
    "                                    \n",
    "            # create arrays of medians and quartiles~ \n",
    "            lower, upper = 0.5, 99.5                \n",
    "            redshifts.append( redshift )\n",
    "            \n",
    "            medfrac_majdw_cut.append( np.median( frac_majdw_cut ) )\n",
    "            medfrac_mindw_cut.append( np.median( frac_mindw_cut ) )\n",
    "            medfrac_majma_cut.append( np.median( frac_majma_cut ) )\n",
    "            medfrac_minma_cut.append( np.median( frac_minma_cut ) )\n",
    "            medfrac_majdw_recovered.append( np.median( frac_majdw_recovered ) )\n",
    "            medfrac_mindw_recovered.append( np.median( frac_mindw_recovered ) )\n",
    "            medfrac_majma_recovered.append( np.median( frac_majma_recovered ) )\n",
    "            medfrac_minma_recovered.append( np.median( frac_minma_recovered ) )\n",
    "            \n",
    "            quartfrac_majdw_cut.append( np.percentile( frac_majdw_cut, [lower,upper] ) )\n",
    "            quartfrac_mindw_cut.append( np.percentile( frac_mindw_cut, [lower,upper] ) )\n",
    "            quartfrac_majma_cut.append( np.percentile( frac_majma_cut, [lower,upper] ) )\n",
    "            quartfrac_minma_cut.append( np.percentile( frac_minma_cut, [lower,upper] ) )\n",
    "            quartfrac_majdw_recovered.append( np.percentile( frac_majdw_recovered, [lower,upper] ) )\n",
    "            quartfrac_mindw_recovered.append( np.percentile( frac_mindw_recovered, [lower,upper] ) )\n",
    "            quartfrac_majma_recovered.append( np.percentile( frac_majma_recovered, [lower,upper] ) )\n",
    "            quartfrac_minma_recovered.append( np.percentile( frac_minma_recovered, [lower,upper] ) )\n",
    "                                   \n",
    "        except KeyError:\n",
    "            if errorprint: print(f'skipping {snap} for KeyError. Please debug')\n",
    "            continue\n",
    "            \n",
    "        except EmptyFile:\n",
    "            if errorprint: print(f\"skipping {snap}, empty file\")\n",
    "            continue\n",
    "            \n",
    "        except SkipRedshift:\n",
    "            if errorprint: print(f\"skipping {snap}, redshift out of range\")\n",
    "                \n",
    "    count_dictionary = {\n",
    "            \"z\": np.array(redshifts),\n",
    "        \n",
    "            \"Median Major Dwarf\": np.array(medfrac_majdw_cut),\n",
    "            \"Median Minor Dwarf\": np.array(medfrac_mindw_cut),\n",
    "            \"Median Major Massive\": np.array(medfrac_majma_cut),\n",
    "            \"Median Minor Massive\": np.array(medfrac_minma_cut),\n",
    "            \"Frac Major Dwarf Recovered\": np.array(medfrac_majdw_recovered),\n",
    "            \"Frac Minor Dwarf Recovered\": np.array(medfrac_mindw_recovered),\n",
    "            \"Frac Major Massive Recovered\": np.array(medfrac_majma_recovered),\n",
    "            \"Frac Minor Massive Recovered\": np.array(medfrac_minma_recovered),\n",
    "        \n",
    "            \"Quartile Major Dwarf\": np.array(quartfrac_majdw_cut),\n",
    "            \"Quartile Minor Dwarf\": np.array(quartfrac_mindw_cut),\n",
    "            \"Quartile Major Massive\": np.array(quartfrac_majma_cut),\n",
    "            \"Quartile Minor Massive\": np.array(quartfrac_minma_cut),\n",
    "            \"Quartile Major Dwarf Recovered\": np.array(quartfrac_majdw_recovered),\n",
    "            \"Quartile Minor Dwarf Recovered\": np.array(quartfrac_mindw_recovered),\n",
    "            \"Quartile Major Massive Recovered\": np.array(quartfrac_majma_recovered),\n",
    "            \"Quartile Minor Massive Recovered\": np.array(quartfrac_minma_recovered)\n",
    "            }\n",
    "    \n",
    "    return count_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0597fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairfracdata_vircut(reals, vircut):\n",
    "    #check if files exists\n",
    "    filepath = f\"{paths.path_plotdata}pairfrac_vircut_full.hdf5\"\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"file does not exist...\")\n",
    "        print(\"creating file\")\n",
    "        f = h5py.File(filepath, 'w')\n",
    "        print(\"file created successfully. adding header...\")\n",
    "        header_dict = {\"Simulation\":\"TNG100-1 (Hydro)\",\n",
    "                      \"1000 Realization - quartile range\":\"0.5-99.5%\"}\n",
    "\n",
    "\n",
    "        dset = f.create_group('/Header')\n",
    "        for key in header_dict.keys():\n",
    "            dset.attrs[key] = header_dict[key]\n",
    "            \n",
    "        print(\"header added successfully\")\n",
    "    else:\n",
    "        print(\"file exists...\")\n",
    "        f = h5py.File(filepath, 'r+')\n",
    "        \n",
    "        \n",
    "    print(\"checking to see if data exists for this number of realizations\")\n",
    "    \n",
    "    if f.get(f\"{reals} Realizations/Vircut {vircut}\") is not None:\n",
    "        print(\"data already exists!\")\n",
    "        f.close()\n",
    "              \n",
    "    else:\n",
    "        print(\"data does not exist...\")\n",
    "        print(\"creating data tables...\")\n",
    "        \n",
    "        ratios = get_pairfrac_vircut(reals,vircut)\n",
    "\n",
    "        for key, val in ratios.items():\n",
    "            val = np.array(val)\n",
    "            dset = f.create_dataset(f'/{reals} Realizations/Vircut {vircut}/{key}', \n",
    "                                    shape=val.shape,\n",
    "                                    dtype=val.dtype)\n",
    "            dset[:] = val\n",
    "        print(\"data saved\")        \n",
    "        f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "554c1378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** starting 10 realizations ****\n",
      "virial is: 0.25\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "virial is: 0.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "virial is: 1\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "virial is: 1.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "virial is: 2\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "virial is: 2.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data already exists!\n",
      "**** starting 100 realizations ****\n",
      "virial is: 0.25\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 0.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 1\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 1.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 2\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 2.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "**** starting 1000 realizations ****\n",
      "virial is: 0.25\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 0.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 1\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 1.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 2\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n",
      "virial is: 2.5\n",
      "file exists...\n",
      "checking to see if data exists for this number of realizations\n",
      "data does not exist...\n",
      "creating data tables...\n",
      "data saved\n"
     ]
    }
   ],
   "source": [
    "vircuts = [0.25,0.5,1,1.5,2,2.5]\n",
    "reals = [10, 100, 1000]\n",
    "\n",
    "for real in reals:\n",
    "    print(f\"**** starting {real} realizations ****\")\n",
    "    for vircut in vircuts:\n",
    "        print(f\"virial is: {vircut}\")\n",
    "\n",
    "        make_pairfracdata_vircut(real,vircut)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2750786",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "for vircut in [0.5,1,1.5,2,2.5]:\n",
    "    print(f\"sepcut is: {vircut}\")\n",
    "    print(\"**** starting 10 ****\")\n",
    "    make_pairfracdata_sepcut(10,vircut)\n",
    "    \n",
    "    print(\"**** starting 100 ****\")\n",
    "    make_pairfracdata_sepcut(100,vircut)    \n",
    "    \n",
    "    print(\"**** starting 1000 ****\")\n",
    "    make_pairfracdata_sepcut(1000,vircut)    \n",
    "    \n",
    "# make_pairfracdata_sepcut(10,50) #\n",
    "# make_pairfracdata_sepcut(10,70) # Snyder 2023\n",
    "# make_pairfracdata_sepcut(10,100) #\n",
    "# make_pairfracdata_sepcut(10,150) # Besla 2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d2c1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = get_pairfrac_sepcut(10, 50, errorprint=False, redshiftcutoff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a9a372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['z', 'Median Major Dwarf', 'Median Minor Dwarf', 'Median Major Massive', 'Median Minor Massive', 'Frac Major Dwarf Recovered', 'Frac Minor Dwarf Recovered', 'Frac Major Massive Recovered', 'Frac Minor Massive Recovered', 'Quartile Major Dwarf', 'Quartile Minor Dwarf', 'Quartile Major Massive', 'Quartile Minor Massive', 'Quartile Major Dwarf Recovered'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c0e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07847577, 0.07887069, 0.07339582, 0.07194664, 0.06953869,\n",
       "       0.06611652, 0.06393404, 0.06407182, 0.06183954, 0.059131  ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester['Median Major Dwarf'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72f7917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60982658, 0.60493624, 0.57076118, 0.56065726, 0.54203146,\n",
       "       0.53058157, 0.50883725, 0.51007527, 0.50957423, 0.48280846,\n",
       "       0.47446969, 0.47764149, 0.47054536, 0.47523125, 0.47021844,\n",
       "       0.45184615, 0.44632103, 0.44472973, 0.43105776, 0.42673449,\n",
       "       0.42294315, 0.40412224, 0.407767  , 0.39735095, 0.40086798,\n",
       "       0.39142738, 0.38662259, 0.38982796, 0.36373714, 0.35531717,\n",
       "       0.34891549, 0.35912805, 0.35882905, 0.3616776 , 0.34056667,\n",
       "       0.3283059 , 0.33783288, 0.32227173, 0.33021008, 0.32031746,\n",
       "       0.32287681, 0.31488475, 0.32011985, 0.30974076, 0.31443362,\n",
       "       0.29750466, 0.29782689, 0.29577776, 0.28338898, 0.28054239,\n",
       "       0.29858629, 0.29595993, 0.27391466, 0.26358615, 0.2747796 ,\n",
       "       0.26798645, 0.26559285, 0.2548034 , 0.25210515, 0.26633128,\n",
       "       0.25607339, 0.25052433, 0.26670385, 0.24497241, 0.2539489 ,\n",
       "       0.25548204, 0.23159256, 0.23658268, 0.21869015, 0.22241378,\n",
       "       0.2175508 , 0.21192839, 0.21182655, 0.20560499, 0.20520349,\n",
       "       0.19833196, 0.19638404, 0.18279507, 0.20198977])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester[\"Frac Major Dwarf Recovered\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44f4a8",
   "metadata": {},
   "source": [
    "# Comparison plot (lit review) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa2fde92",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = [0.25, 0.75, 1.25, \n",
    "            1.75, 2.25, 3, \n",
    "            4, 5.5]\n",
    "\n",
    "subfind_full = [0.28408361844787400, 0.3967792682835680, 0.3105562443495830, \n",
    "                0.2548518480347080, 0.43983420079419700, 0.34714255831491100, \n",
    "                0.3711320119287430, 0.21564351220864500]\n",
    "\n",
    "subfind_detection = [0.16008590055114600, 0.3301736741546460, 0.26277792288463100, \n",
    "                     0.23118845501327600, 0.3413915132625050, 0.2499329172046900, \n",
    "                     0.310556244349583, 0.12883571609350400]\n",
    "\n",
    "source_detection = [0.48756106896697400, 0.3732044346340160, 0.3376105125784730, \n",
    "                    0.28093731775220400, 0.41255098653991600, 0.310556244349583, \n",
    "                    0.35993769212646000, 0.17258426971826300]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tart",
   "language": "python",
   "name": "tart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "753px",
    "left": "38px",
    "top": "111.133px",
    "width": "185px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
